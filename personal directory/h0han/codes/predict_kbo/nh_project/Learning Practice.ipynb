{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SB_D</th>\n",
       "      <th>SB_R</th>\n",
       "      <th>ERA</th>\n",
       "      <th>ER</th>\n",
       "      <th>CG</th>\n",
       "      <th>SHO</th>\n",
       "      <th>RA</th>\n",
       "      <th>R</th>\n",
       "      <th>AB</th>\n",
       "      <th>H</th>\n",
       "      <th>...</th>\n",
       "      <th>FP</th>\n",
       "      <th>SV</th>\n",
       "      <th>IPOuts</th>\n",
       "      <th>HA</th>\n",
       "      <th>HRA</th>\n",
       "      <th>BBA</th>\n",
       "      <th>SOA</th>\n",
       "      <th>E</th>\n",
       "      <th>DP</th>\n",
       "      <th>W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124</td>\n",
       "      <td>64</td>\n",
       "      <td>5.76</td>\n",
       "      <td>827</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.32</td>\n",
       "      <td>826</td>\n",
       "      <td>5109</td>\n",
       "      <td>1478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977</td>\n",
       "      <td>24</td>\n",
       "      <td>3878</td>\n",
       "      <td>1520</td>\n",
       "      <td>155</td>\n",
       "      <td>634</td>\n",
       "      <td>976</td>\n",
       "      <td>124</td>\n",
       "      <td>229</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136</td>\n",
       "      <td>101</td>\n",
       "      <td>4.97</td>\n",
       "      <td>705</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5.54</td>\n",
       "      <td>803</td>\n",
       "      <td>4999</td>\n",
       "      <td>1429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979</td>\n",
       "      <td>38</td>\n",
       "      <td>3828</td>\n",
       "      <td>1456</td>\n",
       "      <td>131</td>\n",
       "      <td>561</td>\n",
       "      <td>965</td>\n",
       "      <td>111</td>\n",
       "      <td>219</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>96</td>\n",
       "      <td>5.92</td>\n",
       "      <td>838</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.55</td>\n",
       "      <td>672</td>\n",
       "      <td>4963</td>\n",
       "      <td>1369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976</td>\n",
       "      <td>27</td>\n",
       "      <td>3819</td>\n",
       "      <td>1593</td>\n",
       "      <td>145</td>\n",
       "      <td>560</td>\n",
       "      <td>980</td>\n",
       "      <td>130</td>\n",
       "      <td>264</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>121</td>\n",
       "      <td>5.04</td>\n",
       "      <td>721</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5.64</td>\n",
       "      <td>786</td>\n",
       "      <td>5051</td>\n",
       "      <td>1464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981</td>\n",
       "      <td>34</td>\n",
       "      <td>3863</td>\n",
       "      <td>1426</td>\n",
       "      <td>122</td>\n",
       "      <td>539</td>\n",
       "      <td>909</td>\n",
       "      <td>103</td>\n",
       "      <td>217</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>145</td>\n",
       "      <td>5.63</td>\n",
       "      <td>792</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6.15</td>\n",
       "      <td>777</td>\n",
       "      <td>5001</td>\n",
       "      <td>1439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983</td>\n",
       "      <td>27</td>\n",
       "      <td>3799</td>\n",
       "      <td>1486</td>\n",
       "      <td>161</td>\n",
       "      <td>585</td>\n",
       "      <td>1009</td>\n",
       "      <td>91</td>\n",
       "      <td>229</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SB_D  SB_R   ERA   ER  CG  SHO    RA    R    AB     H ...     FP  SV  \\\n",
       "0   124    64  5.76  827   1    2  6.32  826  5109  1478 ...  0.977  24   \n",
       "1   136   101  4.97  705   7    5  5.54  803  4999  1429 ...  0.979  38   \n",
       "2   115    96  5.92  838   1    2  6.55  672  4963  1369 ...  0.976  27   \n",
       "3    80   121  5.04  721   2    5  5.64  786  5051  1464 ...  0.981  34   \n",
       "4    90   145  5.63  792   2    5  6.15  777  5001  1439 ...  0.983  27   \n",
       "\n",
       "   IPOuts    HA  HRA  BBA   SOA    E   DP   W  \n",
       "0    3878  1520  155  634   976  124  229  66  \n",
       "1    3828  1456  131  561   965  111  219  70  \n",
       "2    3819  1593  145  560   980  130  264  53  \n",
       "3    3863  1426  122  539   909  103  217  71  \n",
       "4    3799  1486  161  585  1009   91  229  66  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('practice.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(df['W'])\n",
    "plt.xlabel('Wins')\n",
    "plt.title('Distribution of Wins')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SB_D      0.406149\n",
       "SB_R      0.623423\n",
       "ERA      -0.313221\n",
       "ER        0.503294\n",
       "CG        0.209995\n",
       "SHO       0.473576\n",
       "RA       -0.339742\n",
       "R         0.876900\n",
       "AB        0.838537\n",
       "H         0.867653\n",
       "2B        0.818614\n",
       "3B        0.607394\n",
       "HR        0.678608\n",
       "BB        0.627698\n",
       "SO        0.806856\n",
       "Rank     -0.522707\n",
       "G         0.828139\n",
       "FP        0.109302\n",
       "SV        0.922951\n",
       "IPOuts    0.837875\n",
       "HA        0.732641\n",
       "HRA       0.491891\n",
       "BBA       0.627698\n",
       "SOA       0.806856\n",
       "E         0.664863\n",
       "DP        0.259039\n",
       "W         1.000000\n",
       "Name: W, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[124.  ,  64.  ,   5.76, ..., 976.  , 124.  , 229.  ],\n",
       "       [136.  , 101.  ,   4.97, ..., 965.  , 111.  , 219.  ],\n",
       "       [115.  ,  96.  ,   5.92, ..., 980.  , 130.  , 264.  ],\n",
       "       ...,\n",
       "       [ 82.  ,  44.  ,   5.46, ..., 447.  ,  46.  ,  53.  ],\n",
       "       [ 34.  ,  81.  ,   4.61, ..., 401.  ,  43.  ,  57.  ],\n",
       "       [ 54.  ,  65.  ,   4.37, ..., 425.  ,  47.  ,  62.  ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = df.values[:, 0:26]\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66.],\n",
       "       [70.],\n",
       "       [53.],\n",
       "       [71.],\n",
       "       [66.],\n",
       "       [83.],\n",
       "       [93.],\n",
       "       [69.],\n",
       "       [65.],\n",
       "       [77.],\n",
       "       [61.],\n",
       "       [87.],\n",
       "       [50.],\n",
       "       [69.],\n",
       "       [80.],\n",
       "       [79.],\n",
       "       [84.],\n",
       "       [75.],\n",
       "       [55.],\n",
       "       [69.],\n",
       "       [77.],\n",
       "       [70.],\n",
       "       [59.],\n",
       "       [68.],\n",
       "       [68.],\n",
       "       [58.],\n",
       "       [93.],\n",
       "       [78.],\n",
       "       [68.],\n",
       "       [75.],\n",
       "       [58.],\n",
       "       [62.],\n",
       "       [71.],\n",
       "       [79.],\n",
       "       [48.],\n",
       "       [73.],\n",
       "       [88.],\n",
       "       [88.],\n",
       "       [60.],\n",
       "       [86.],\n",
       "       [17.],\n",
       "       [33.],\n",
       "       [31.],\n",
       "       [34.],\n",
       "       [30.],\n",
       "       [42.],\n",
       "       [38.],\n",
       "       [21.],\n",
       "       [34.],\n",
       "       [38.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = df.values[:, [26]]\n",
    "y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = scaler.fit_transform(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45, 26), (45, 1), (5, 26), (5, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.1, random_state=7)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기울기: [[ -0.18236276   0.14671256   8.20986015 -18.69091666  -1.17798803\n",
      "    0.67714682  -2.27818537  18.94768164   6.7835888  -13.71753123\n",
      "    1.41563051  -2.14874987  -1.44882931   1.61061913  -2.10618722\n",
      "   -3.74254544  15.82163502   0.96382358   5.75196783  -6.85763062\n",
      "    8.25212526  -0.76920751   1.61061913  -2.10618722   2.74777861\n",
      "   -1.52243656]]\n",
      "절편: [63.21471165]\n",
      "훈련 정확도:0.99039\n",
      "테스트 정확도:0.92562\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "print(\"기울기:\", lr.coef_)  # [0.39390555]\n",
    "print(\"절편:\", lr.intercept_)  # -0.03180434302675973\n",
    "print(\"훈련 정확도:{:.5f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"테스트 정확도:{:.5f}\".format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45 samples, validate on 5 samples\n",
      "Epoch 1/100\n",
      "45/45 [==============================] - 0s 8ms/step - loss: 3588.7819 - mae: 55.5725 - val_loss: 1642.8216 - val_mae: 36.7683\n",
      "Epoch 2/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 577.9646 - mae: 20.1139 - val_loss: 205.0107 - val_mae: 10.8853\n",
      "Epoch 3/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 134.6940 - mae: 8.9529 - val_loss: 203.8904 - val_mae: 12.0975\n",
      "Epoch 4/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 111.8343 - mae: 8.2153 - val_loss: 99.7252 - val_mae: 7.9215\n",
      "Epoch 5/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 90.9615 - mae: 6.9512 - val_loss: 97.0557 - val_mae: 8.3085\n",
      "Epoch 6/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 83.0984 - mae: 6.9785 - val_loss: 47.7784 - val_mae: 6.0175\n",
      "Epoch 7/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 61.1330 - mae: 6.3137 - val_loss: 41.9720 - val_mae: 5.0293\n",
      "Epoch 8/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 50.5156 - mae: 5.6376 - val_loss: 58.3016 - val_mae: 6.7502\n",
      "Epoch 9/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 43.3422 - mae: 5.2394 - val_loss: 40.6953 - val_mae: 4.5040\n",
      "Epoch 10/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 35.7148 - mae: 4.8989 - val_loss: 53.8128 - val_mae: 6.2768\n",
      "Epoch 11/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 31.4847 - mae: 4.1708 - val_loss: 28.8071 - val_mae: 4.1284\n",
      "Epoch 12/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 33.7027 - mae: 4.3672 - val_loss: 40.8356 - val_mae: 5.3544\n",
      "Epoch 13/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 20.6840 - mae: 3.6206 - val_loss: 90.1731 - val_mae: 7.2163\n",
      "Epoch 14/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 27.2695 - mae: 4.5409 - val_loss: 52.8354 - val_mae: 5.9582\n",
      "Epoch 15/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 17.4932 - mae: 3.2042 - val_loss: 64.6153 - val_mae: 6.4349\n",
      "Epoch 16/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 15.2698 - mae: 3.3046 - val_loss: 42.5563 - val_mae: 5.8870\n",
      "Epoch 17/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 14.4280 - mae: 3.0522 - val_loss: 76.8990 - val_mae: 7.9334\n",
      "Epoch 18/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 19.8829 - mae: 3.5863 - val_loss: 57.1130 - val_mae: 5.7965\n",
      "Epoch 19/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 17.4544 - mae: 3.5301 - val_loss: 48.6855 - val_mae: 5.9971\n",
      "Epoch 20/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 10.4842 - mae: 2.5453 - val_loss: 67.7315 - val_mae: 6.4201\n",
      "Epoch 21/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 17.1830 - mae: 3.2999 - val_loss: 74.5205 - val_mae: 7.7343\n",
      "Epoch 22/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 10.9906 - mae: 2.4824 - val_loss: 91.7396 - val_mae: 8.3156\n",
      "Epoch 23/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 13.1110 - mae: 2.9756 - val_loss: 67.8647 - val_mae: 6.9604\n",
      "Epoch 24/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 11.9092 - mae: 2.8218 - val_loss: 49.1539 - val_mae: 6.0000\n",
      "Epoch 25/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 10.8362 - mae: 2.5911 - val_loss: 85.0507 - val_mae: 7.8123\n",
      "Epoch 26/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 12.7754 - mae: 2.9481 - val_loss: 70.8246 - val_mae: 7.1067\n",
      "Epoch 27/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 10.5098 - mae: 2.5022 - val_loss: 38.3576 - val_mae: 5.6629\n",
      "Epoch 28/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 13.6816 - mae: 2.7756 - val_loss: 48.2296 - val_mae: 5.9452\n",
      "Epoch 29/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 11.6891 - mae: 2.4653 - val_loss: 76.6012 - val_mae: 7.0338\n",
      "Epoch 30/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 5.9149 - mae: 1.9234 - val_loss: 62.5765 - val_mae: 6.5447\n",
      "Epoch 31/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 11.1692 - mae: 2.5416 - val_loss: 75.7586 - val_mae: 7.7525\n",
      "Epoch 32/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 10.3535 - mae: 2.4311 - val_loss: 70.0573 - val_mae: 6.7851\n",
      "Epoch 33/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 11.0277 - mae: 2.7393 - val_loss: 80.3524 - val_mae: 6.3552\n",
      "Epoch 34/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 11.2570 - mae: 2.6908 - val_loss: 84.5183 - val_mae: 7.6001\n",
      "Epoch 35/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 11.4457 - mae: 2.5432 - val_loss: 68.7060 - val_mae: 7.3763\n",
      "Epoch 36/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 9.3573 - mae: 2.4020 - val_loss: 76.6949 - val_mae: 6.4516\n",
      "Epoch 37/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.7478 - mae: 2.2798 - val_loss: 79.5047 - val_mae: 7.5442\n",
      "Epoch 38/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.8702 - mae: 2.2995 - val_loss: 61.5605 - val_mae: 6.7155\n",
      "Epoch 39/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 11.5089 - mae: 2.5696 - val_loss: 55.7197 - val_mae: 6.8698\n",
      "Epoch 40/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 10.4474 - mae: 2.5903 - val_loss: 74.9304 - val_mae: 7.3439\n",
      "Epoch 41/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 7.7882 - mae: 2.3948 - val_loss: 92.5416 - val_mae: 7.6547\n",
      "Epoch 42/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 9.0238 - mae: 2.2415 - val_loss: 93.8523 - val_mae: 8.0983\n",
      "Epoch 43/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 9.9526 - mae: 2.4744 - val_loss: 76.6148 - val_mae: 7.6576\n",
      "Epoch 44/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 10.1060 - mae: 2.5665 - val_loss: 65.0399 - val_mae: 6.7618\n",
      "Epoch 45/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.6676 - mae: 2.1828 - val_loss: 54.7090 - val_mae: 6.4811\n",
      "Epoch 46/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 9.4459 - mae: 2.3183 - val_loss: 74.5728 - val_mae: 7.1858\n",
      "Epoch 47/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.0727 - mae: 2.1810 - val_loss: 77.6215 - val_mae: 7.1466\n",
      "Epoch 48/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 9.4284 - mae: 2.5895 - val_loss: 74.5452 - val_mae: 7.5580\n",
      "Epoch 49/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 9.7714 - mae: 2.4134 - val_loss: 85.6464 - val_mae: 7.9042\n",
      "Epoch 50/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.7182 - mae: 2.3068 - val_loss: 77.4436 - val_mae: 7.8437\n",
      "Epoch 51/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 9.6963 - mae: 2.4821 - val_loss: 44.8042 - val_mae: 5.3783\n",
      "Epoch 52/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 7.1660 - mae: 2.1646 - val_loss: 87.5353 - val_mae: 7.5218\n",
      "Epoch 53/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 11.0330 - mae: 2.4221 - val_loss: 59.1067 - val_mae: 6.7030\n",
      "Epoch 54/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.7246 - mae: 2.3299 - val_loss: 72.2804 - val_mae: 7.3254\n",
      "Epoch 55/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 7.8994 - mae: 2.2547 - val_loss: 59.7016 - val_mae: 6.7106\n",
      "Epoch 56/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.5656 - mae: 2.4174 - val_loss: 71.2540 - val_mae: 6.6230\n",
      "Epoch 57/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.5318 - mae: 2.3514 - val_loss: 80.8928 - val_mae: 7.8495\n",
      "Epoch 58/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 10.8751 - mae: 2.7384 - val_loss: 55.6863 - val_mae: 6.7039\n",
      "Epoch 59/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 6.6174 - mae: 1.9578 - val_loss: 66.5305 - val_mae: 7.5610\n",
      "Epoch 60/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 7.9943 - mae: 2.3696 - val_loss: 50.1344 - val_mae: 6.0290\n",
      "Epoch 61/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 7.6863 - mae: 2.1725 - val_loss: 71.8095 - val_mae: 7.5335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.4155 - mae: 2.3059 - val_loss: 80.6991 - val_mae: 7.6100\n",
      "Epoch 63/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.7453 - mae: 2.4297 - val_loss: 104.8158 - val_mae: 9.5374\n",
      "Epoch 64/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 6.4901 - mae: 1.9799 - val_loss: 100.9656 - val_mae: 9.3842\n",
      "Epoch 65/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 10.5507 - mae: 2.5463 - val_loss: 70.1622 - val_mae: 7.3469\n",
      "Epoch 66/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 6.8742 - mae: 1.9715 - val_loss: 68.8941 - val_mae: 7.0924\n",
      "Epoch 67/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 6.7948 - mae: 2.1792 - val_loss: 87.3396 - val_mae: 7.2687\n",
      "Epoch 68/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 9.4450 - mae: 2.2660 - val_loss: 67.0756 - val_mae: 7.7546\n",
      "Epoch 69/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 9.6906 - mae: 2.6051 - val_loss: 71.2228 - val_mae: 7.5045\n",
      "Epoch 70/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 5.7045 - mae: 1.8170 - val_loss: 82.9928 - val_mae: 7.8699\n",
      "Epoch 71/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 6.2784 - mae: 1.8897 - val_loss: 98.0191 - val_mae: 8.9103\n",
      "Epoch 72/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 11.4353 - mae: 2.5006 - val_loss: 101.5057 - val_mae: 8.1375\n",
      "Epoch 73/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 7.2300 - mae: 2.2896 - val_loss: 77.0531 - val_mae: 8.1521\n",
      "Epoch 74/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 6.9190 - mae: 2.1701 - val_loss: 68.1923 - val_mae: 7.4386\n",
      "Epoch 75/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 7.2338 - mae: 2.0719 - val_loss: 85.2847 - val_mae: 7.4653\n",
      "Epoch 76/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 11.2307 - mae: 2.5654 - val_loss: 72.4342 - val_mae: 7.4041\n",
      "Epoch 77/100\n",
      "45/45 [==============================] - 0s 1ms/step - loss: 5.4155 - mae: 1.9217 - val_loss: 68.4857 - val_mae: 7.0291\n",
      "Epoch 78/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.0133 - mae: 2.2619 - val_loss: 68.6495 - val_mae: 7.1602\n",
      "Epoch 79/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 7.9178 - mae: 2.2765 - val_loss: 72.8309 - val_mae: 7.2312\n",
      "Epoch 80/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 7.8336 - mae: 2.2569 - val_loss: 76.6919 - val_mae: 8.0476\n",
      "Epoch 81/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 6.2223 - mae: 2.0268 - val_loss: 52.9197 - val_mae: 6.9049\n",
      "Epoch 82/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.5512 - mae: 2.1159 - val_loss: 80.6869 - val_mae: 7.7832\n",
      "Epoch 83/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 6.7324 - mae: 2.1114 - val_loss: 70.2135 - val_mae: 7.0457\n",
      "Epoch 84/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 9.2987 - mae: 2.4224 - val_loss: 64.7681 - val_mae: 7.6183\n",
      "Epoch 85/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 6.8165 - mae: 2.0202 - val_loss: 89.9434 - val_mae: 7.4419\n",
      "Epoch 86/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 6.3740 - mae: 2.0384 - val_loss: 88.5451 - val_mae: 8.6341\n",
      "Epoch 87/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 6.6291 - mae: 1.9207 - val_loss: 94.5151 - val_mae: 8.4027\n",
      "Epoch 88/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.3820 - mae: 2.3651 - val_loss: 75.4877 - val_mae: 7.7179\n",
      "Epoch 89/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 6.3041 - mae: 1.9198 - val_loss: 87.6842 - val_mae: 8.3720\n",
      "Epoch 90/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 7.1220 - mae: 2.0105 - val_loss: 82.6206 - val_mae: 8.3324\n",
      "Epoch 91/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 7.6618 - mae: 2.1484 - val_loss: 73.2458 - val_mae: 7.3461\n",
      "Epoch 92/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 5.9260 - mae: 1.8712 - val_loss: 96.4681 - val_mae: 8.6249\n",
      "Epoch 93/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 7.3081 - mae: 1.9836 - val_loss: 87.1725 - val_mae: 8.3467\n",
      "Epoch 94/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 6.8304 - mae: 2.1258 - val_loss: 94.8847 - val_mae: 8.7618\n",
      "Epoch 95/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 6.6743 - mae: 1.9850 - val_loss: 69.9647 - val_mae: 7.6432\n",
      "Epoch 96/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.7155 - mae: 2.2114 - val_loss: 79.6644 - val_mae: 7.4328\n",
      "Epoch 97/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 5.7858 - mae: 1.7872 - val_loss: 82.4587 - val_mae: 8.0474\n",
      "Epoch 98/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 10.4932 - mae: 2.3582 - val_loss: 74.4783 - val_mae: 7.7732\n",
      "Epoch 99/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 5.6426 - mae: 1.8951 - val_loss: 86.4438 - val_mae: 8.2782\n",
      "Epoch 100/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 6.8175 - mae: 1.8348 - val_loss: 91.1766 - val_mae: 8.0802\n",
      "Wall time: 9.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(26,)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='rmsprop', metrics=['mae'])\n",
    "\n",
    "hist = model.fit(X_train, y_train, epochs=100, batch_size=1, validation_data=(X_test, y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
