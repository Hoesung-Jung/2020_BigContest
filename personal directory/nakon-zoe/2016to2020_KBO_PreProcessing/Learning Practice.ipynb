{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SB_D</th>\n",
       "      <th>SB_R</th>\n",
       "      <th>ERA</th>\n",
       "      <th>ER</th>\n",
       "      <th>CG</th>\n",
       "      <th>SHO</th>\n",
       "      <th>RA</th>\n",
       "      <th>R</th>\n",
       "      <th>AB</th>\n",
       "      <th>H</th>\n",
       "      <th>...</th>\n",
       "      <th>FP</th>\n",
       "      <th>SV</th>\n",
       "      <th>IPOuts</th>\n",
       "      <th>HA</th>\n",
       "      <th>HRA</th>\n",
       "      <th>BBA</th>\n",
       "      <th>SOA</th>\n",
       "      <th>E</th>\n",
       "      <th>DP</th>\n",
       "      <th>W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>64</td>\n",
       "      <td>5.76</td>\n",
       "      <td>827</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.32</td>\n",
       "      <td>826</td>\n",
       "      <td>5109</td>\n",
       "      <td>1478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977</td>\n",
       "      <td>24</td>\n",
       "      <td>3878</td>\n",
       "      <td>1520</td>\n",
       "      <td>155</td>\n",
       "      <td>634</td>\n",
       "      <td>976</td>\n",
       "      <td>124</td>\n",
       "      <td>229</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>101</td>\n",
       "      <td>4.97</td>\n",
       "      <td>705</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5.54</td>\n",
       "      <td>803</td>\n",
       "      <td>4999</td>\n",
       "      <td>1429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979</td>\n",
       "      <td>38</td>\n",
       "      <td>3828</td>\n",
       "      <td>1456</td>\n",
       "      <td>131</td>\n",
       "      <td>561</td>\n",
       "      <td>965</td>\n",
       "      <td>111</td>\n",
       "      <td>219</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "      <td>96</td>\n",
       "      <td>5.92</td>\n",
       "      <td>838</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.55</td>\n",
       "      <td>672</td>\n",
       "      <td>4963</td>\n",
       "      <td>1369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976</td>\n",
       "      <td>27</td>\n",
       "      <td>3819</td>\n",
       "      <td>1593</td>\n",
       "      <td>145</td>\n",
       "      <td>560</td>\n",
       "      <td>980</td>\n",
       "      <td>130</td>\n",
       "      <td>264</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>121</td>\n",
       "      <td>5.04</td>\n",
       "      <td>721</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5.64</td>\n",
       "      <td>786</td>\n",
       "      <td>5051</td>\n",
       "      <td>1464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981</td>\n",
       "      <td>34</td>\n",
       "      <td>3863</td>\n",
       "      <td>1426</td>\n",
       "      <td>122</td>\n",
       "      <td>539</td>\n",
       "      <td>909</td>\n",
       "      <td>103</td>\n",
       "      <td>217</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>145</td>\n",
       "      <td>5.63</td>\n",
       "      <td>792</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6.15</td>\n",
       "      <td>777</td>\n",
       "      <td>5001</td>\n",
       "      <td>1439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983</td>\n",
       "      <td>27</td>\n",
       "      <td>3799</td>\n",
       "      <td>1486</td>\n",
       "      <td>161</td>\n",
       "      <td>585</td>\n",
       "      <td>1009</td>\n",
       "      <td>91</td>\n",
       "      <td>229</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SB_D  SB_R   ERA   ER  CG  SHO    RA    R    AB     H  ...     FP  SV  \\\n",
       "0   124    64  5.76  827   1    2  6.32  826  5109  1478  ...  0.977  24   \n",
       "1   136   101  4.97  705   7    5  5.54  803  4999  1429  ...  0.979  38   \n",
       "2   115    96  5.92  838   1    2  6.55  672  4963  1369  ...  0.976  27   \n",
       "3    80   121  5.04  721   2    5  5.64  786  5051  1464  ...  0.981  34   \n",
       "4    90   145  5.63  792   2    5  6.15  777  5001  1439  ...  0.983  27   \n",
       "\n",
       "   IPOuts    HA  HRA  BBA   SOA    E   DP   W  \n",
       "0    3878  1520  155  634   976  124  229  66  \n",
       "1    3828  1456  131  561   965  111  219  70  \n",
       "2    3819  1593  145  560   980  130  264  53  \n",
       "3    3863  1426  122  539   909  103  217  71  \n",
       "4    3799  1486  161  585  1009   91  229  66  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('practice.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(df['W'])\n",
    "plt.xlabel('Wins')\n",
    "plt.title('Distribution of Wins')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SB_D      0.406149\n",
       "SB_R      0.623423\n",
       "ERA      -0.313221\n",
       "ER        0.503294\n",
       "CG        0.209995\n",
       "SHO       0.473576\n",
       "RA       -0.339742\n",
       "R         0.876900\n",
       "AB        0.838537\n",
       "H         0.867653\n",
       "2B        0.818614\n",
       "3B        0.607394\n",
       "HR        0.678608\n",
       "BB        0.627698\n",
       "SO        0.806856\n",
       "Rank     -0.522707\n",
       "G         0.828139\n",
       "FP        0.109302\n",
       "SV        0.922951\n",
       "IPOuts    0.837875\n",
       "HA        0.732641\n",
       "HRA       0.491891\n",
       "BBA       0.627698\n",
       "SOA       0.806856\n",
       "E         0.664863\n",
       "DP        0.259039\n",
       "W         1.000000\n",
       "Name: W, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[124.  ,  64.  ,   5.76, ..., 976.  , 124.  , 229.  ],\n",
       "       [136.  , 101.  ,   4.97, ..., 965.  , 111.  , 219.  ],\n",
       "       [115.  ,  96.  ,   5.92, ..., 980.  , 130.  , 264.  ],\n",
       "       ...,\n",
       "       [ 82.  ,  44.  ,   5.46, ..., 447.  ,  46.  ,  53.  ],\n",
       "       [ 34.  ,  81.  ,   4.61, ..., 401.  ,  43.  ,  57.  ],\n",
       "       [ 54.  ,  65.  ,   4.37, ..., 425.  ,  47.  ,  62.  ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = df.values[:, 0:26]\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66.],\n",
       "       [70.],\n",
       "       [53.],\n",
       "       [71.],\n",
       "       [66.],\n",
       "       [83.],\n",
       "       [93.],\n",
       "       [69.],\n",
       "       [65.],\n",
       "       [77.],\n",
       "       [61.],\n",
       "       [87.],\n",
       "       [50.],\n",
       "       [69.],\n",
       "       [80.],\n",
       "       [79.],\n",
       "       [84.],\n",
       "       [75.],\n",
       "       [55.],\n",
       "       [69.],\n",
       "       [77.],\n",
       "       [70.],\n",
       "       [59.],\n",
       "       [68.],\n",
       "       [68.],\n",
       "       [58.],\n",
       "       [93.],\n",
       "       [78.],\n",
       "       [68.],\n",
       "       [75.],\n",
       "       [58.],\n",
       "       [62.],\n",
       "       [71.],\n",
       "       [79.],\n",
       "       [48.],\n",
       "       [73.],\n",
       "       [88.],\n",
       "       [88.],\n",
       "       [60.],\n",
       "       [86.],\n",
       "       [17.],\n",
       "       [33.],\n",
       "       [31.],\n",
       "       [34.],\n",
       "       [30.],\n",
       "       [42.],\n",
       "       [38.],\n",
       "       [21.],\n",
       "       [34.],\n",
       "       [38.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = df.values[:, [26]]\n",
    "y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = scaler.fit_transform(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45, 26), (45, 1), (5, 26), (5, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.1, random_state=7)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기울기: [[ -0.18236276   0.14671256   8.20986015 -18.69091666  -1.17798803\n",
      "    0.67714682  -2.27818537  18.94768164   6.7835888  -13.71753123\n",
      "    1.41563051  -2.14874987  -1.44882931   1.61061913  -2.10618722\n",
      "   -3.74254544  15.82163502   0.96382358   5.75196783  -6.85763062\n",
      "    8.25212526  -0.76920751   1.61061913  -2.10618722   2.74777861\n",
      "   -1.52243656]]\n",
      "절편: [63.21471165]\n",
      "훈련 정확도:0.99039\n",
      "테스트 정확도:0.92562\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "print(\"기울기:\", lr.coef_)  # [0.39390555]\n",
    "print(\"절편:\", lr.intercept_)  # -0.03180434302675973\n",
    "print(\"훈련 정확도:{:.5f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"테스트 정확도:{:.5f}\".format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45 samples, validate on 5 samples\n",
      "Epoch 1/100\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 3292.7058 - mae: 53.3754 - val_loss: 1228.9278 - val_mae: 31.7999\n",
      "Epoch 2/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 404.2745 - mae: 15.2876 - val_loss: 172.2822 - val_mae: 11.4978\n",
      "Epoch 3/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 119.6794 - mae: 9.2733 - val_loss: 68.0770 - val_mae: 6.4663\n",
      "Epoch 4/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 82.2885 - mae: 7.1318 - val_loss: 66.2595 - val_mae: 6.7741\n",
      "Epoch 5/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 64.4466 - mae: 6.1571 - val_loss: 57.6507 - val_mae: 6.1885\n",
      "Epoch 6/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 52.7521 - mae: 5.6492 - val_loss: 54.4151 - val_mae: 5.8814\n",
      "Epoch 7/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 47.4245 - mae: 5.5909 - val_loss: 59.7853 - val_mae: 7.3222\n",
      "Epoch 8/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 38.8104 - mae: 5.0243 - val_loss: 46.0087 - val_mae: 6.5170\n",
      "Epoch 9/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 36.6862 - mae: 4.5001 - val_loss: 44.3043 - val_mae: 5.9077\n",
      "Epoch 10/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 21.4364 - mae: 3.7003 - val_loss: 71.7283 - val_mae: 6.0958\n",
      "Epoch 11/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 24.7229 - mae: 3.8678 - val_loss: 56.3637 - val_mae: 6.4167\n",
      "Epoch 12/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 15.9099 - mae: 3.3402 - val_loss: 80.9769 - val_mae: 6.6162\n",
      "Epoch 13/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 23.1728 - mae: 3.8509 - val_loss: 46.7892 - val_mae: 5.1244\n",
      "Epoch 14/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 21.9152 - mae: 3.6810 - val_loss: 53.0926 - val_mae: 6.2955\n",
      "Epoch 15/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 20.6162 - mae: 3.6550 - val_loss: 49.5395 - val_mae: 5.3246\n",
      "Epoch 16/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 14.9885 - mae: 3.0219 - val_loss: 41.8053 - val_mae: 5.5582\n",
      "Epoch 17/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 15.4332 - mae: 3.1525 - val_loss: 73.2653 - val_mae: 6.4779\n",
      "Epoch 18/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 14.0351 - mae: 3.1674 - val_loss: 50.1505 - val_mae: 5.7571\n",
      "Epoch 19/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 16.1855 - mae: 3.1432 - val_loss: 68.8010 - val_mae: 6.4716\n",
      "Epoch 20/100\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 8.9663 - mae: 2.3344 - val_loss: 101.6749 - val_mae: 8.3345\n",
      "Epoch 21/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 10.5925 - mae: 2.4899 - val_loss: 100.0743 - val_mae: 8.3347\n",
      "Epoch 22/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 15.9888 - mae: 3.4339 - val_loss: 72.6066 - val_mae: 7.0550\n",
      "Epoch 23/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 9.3887 - mae: 2.3555 - val_loss: 72.4955 - val_mae: 6.9181\n",
      "Epoch 24/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 14.7954 - mae: 3.2387 - val_loss: 64.0577 - val_mae: 6.6769\n",
      "Epoch 25/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 7.7341 - mae: 2.1561 - val_loss: 62.6854 - val_mae: 7.3320\n",
      "Epoch 26/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 11.8765 - mae: 2.9035 - val_loss: 82.9459 - val_mae: 7.4730\n",
      "Epoch 27/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 11.0700 - mae: 2.7302 - val_loss: 69.2837 - val_mae: 7.4463\n",
      "Epoch 28/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 8.2071 - mae: 2.2580 - val_loss: 63.4950 - val_mae: 6.5834\n",
      "Epoch 29/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 12.2186 - mae: 2.7644 - val_loss: 79.5834 - val_mae: 6.6241\n",
      "Epoch 30/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 6.8793 - mae: 2.1863 - val_loss: 88.1953 - val_mae: 7.9052\n",
      "Epoch 31/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 13.9727 - mae: 2.9295 - val_loss: 49.7457 - val_mae: 5.7772\n",
      "Epoch 32/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 8.7469 - mae: 2.3143 - val_loss: 77.1838 - val_mae: 7.3647\n",
      "Epoch 33/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 8.0930 - mae: 2.1232 - val_loss: 64.9014 - val_mae: 7.0634\n",
      "Epoch 34/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 11.4688 - mae: 2.5956 - val_loss: 75.6920 - val_mae: 6.3003\n",
      "Epoch 35/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 11.0334 - mae: 2.4259 - val_loss: 76.3689 - val_mae: 7.6234\n",
      "Epoch 36/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 10.4379 - mae: 2.6044 - val_loss: 54.4476 - val_mae: 5.9857\n",
      "Epoch 37/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 10.8259 - mae: 2.6331 - val_loss: 85.3100 - val_mae: 7.4667\n",
      "Epoch 38/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 9.0373 - mae: 2.4775 - val_loss: 78.2374 - val_mae: 7.6422\n",
      "Epoch 39/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 6.2827 - mae: 1.9184 - val_loss: 94.3092 - val_mae: 7.6774\n",
      "Epoch 40/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 9.4801 - mae: 2.3519 - val_loss: 96.2793 - val_mae: 7.6783\n",
      "Epoch 41/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 8.5577 - mae: 2.3223 - val_loss: 91.9626 - val_mae: 7.7660\n",
      "Epoch 42/100\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 10.6384 - mae: 2.3884 - val_loss: 99.8066 - val_mae: 7.8498\n",
      "Epoch 43/100\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 7.9953 - mae: 2.2112 - val_loss: 75.4576 - val_mae: 7.0387\n",
      "Epoch 44/100\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 10.8047 - mae: 2.5018 - val_loss: 75.5302 - val_mae: 7.0781\n",
      "Epoch 45/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 7.5592 - mae: 2.3303 - val_loss: 96.9756 - val_mae: 8.4903\n",
      "Epoch 46/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 12.3662 - mae: 2.8779 - val_loss: 83.3593 - val_mae: 7.0111\n",
      "Epoch 47/100\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.5233 - mae: 1.6306 - val_loss: 108.3254 - val_mae: 8.4996\n",
      "Epoch 48/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 7.1814 - mae: 2.0166 - val_loss: 108.2833 - val_mae: 9.3429\n",
      "Epoch 49/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 11.3855 - mae: 2.7628 - val_loss: 96.3093 - val_mae: 8.4226\n",
      "Epoch 50/100\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 7.7954 - mae: 1.9812 - val_loss: 81.2996 - val_mae: 7.8558\n",
      "Epoch 51/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 9.1745 - mae: 2.4756 - val_loss: 101.1806 - val_mae: 8.5390\n",
      "Epoch 52/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 8.3075 - mae: 2.3680 - val_loss: 112.5277 - val_mae: 8.7857\n",
      "Epoch 53/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 7.8119 - mae: 2.2416 - val_loss: 78.9586 - val_mae: 7.5917\n",
      "Epoch 54/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 6.7821 - mae: 2.0806 - val_loss: 104.5188 - val_mae: 9.1740\n",
      "Epoch 55/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 7.2215 - mae: 2.1735 - val_loss: 98.8767 - val_mae: 8.2906\n",
      "Epoch 56/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 9.6900 - mae: 2.4349 - val_loss: 79.1932 - val_mae: 7.5468\n",
      "Epoch 57/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 7.4775 - mae: 2.2409 - val_loss: 109.8568 - val_mae: 9.1211\n",
      "Epoch 58/100\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 7.7894 - mae: 2.2983 - val_loss: 91.7661 - val_mae: 8.0149\n",
      "Epoch 59/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 6.5203 - mae: 1.9491 - val_loss: 65.2165 - val_mae: 6.7174\n",
      "Epoch 60/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 9.4355 - mae: 2.4338 - val_loss: 73.1000 - val_mae: 6.9443\n",
      "Epoch 61/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 10.2345 - mae: 2.1760 - val_loss: 80.6898 - val_mae: 7.2591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 5.4123 - mae: 1.9921 - val_loss: 114.2781 - val_mae: 8.8970\n",
      "Epoch 63/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 8.2974 - mae: 2.4264 - val_loss: 95.3315 - val_mae: 7.9648\n",
      "Epoch 64/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 7.5301 - mae: 2.1583 - val_loss: 72.4074 - val_mae: 6.4390\n",
      "Epoch 65/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 5.9872 - mae: 1.8953 - val_loss: 94.1635 - val_mae: 7.9039\n",
      "Epoch 66/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 9.2148 - mae: 2.4414 - val_loss: 78.1586 - val_mae: 7.0318\n",
      "Epoch 67/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 6.4935 - mae: 2.1282 - val_loss: 80.9708 - val_mae: 7.4174\n",
      "Epoch 68/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 6.8453 - mae: 2.1257 - val_loss: 88.2105 - val_mae: 7.3551\n",
      "Epoch 69/100\n",
      "45/45 [==============================] - 0s 4ms/step - loss: 8.4199 - mae: 2.3154 - val_loss: 106.4473 - val_mae: 8.7603\n",
      "Epoch 70/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 7.7301 - mae: 2.2941 - val_loss: 98.8832 - val_mae: 8.6999\n",
      "Epoch 71/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 7.8236 - mae: 2.1777 - val_loss: 110.9510 - val_mae: 8.1819\n",
      "Epoch 72/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 7.2660 - mae: 2.1894 - val_loss: 122.1650 - val_mae: 9.4718\n",
      "Epoch 73/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 8.7813 - mae: 2.2767 - val_loss: 94.4839 - val_mae: 8.0990\n",
      "Epoch 74/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 6.0394 - mae: 1.9909 - val_loss: 86.3043 - val_mae: 7.8540\n",
      "Epoch 75/100\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 8.9714 - mae: 2.3122 - val_loss: 86.4006 - val_mae: 8.6366\n",
      "Epoch 76/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 9.8189 - mae: 2.5273 - val_loss: 77.8495 - val_mae: 6.8295\n",
      "Epoch 77/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 6.3170 - mae: 2.0543 - val_loss: 78.8528 - val_mae: 7.2370\n",
      "Epoch 78/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 6.3719 - mae: 2.0211 - val_loss: 92.0306 - val_mae: 8.1856\n",
      "Epoch 79/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 6.3652 - mae: 1.9930 - val_loss: 99.5714 - val_mae: 8.0114\n",
      "Epoch 80/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 8.2125 - mae: 2.2918 - val_loss: 92.7733 - val_mae: 8.5759\n",
      "Epoch 81/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 4.5354 - mae: 1.7520 - val_loss: 76.3605 - val_mae: 7.4902\n",
      "Epoch 82/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 8.2105 - mae: 2.1706 - val_loss: 116.7479 - val_mae: 8.6513\n",
      "Epoch 83/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 7.7087 - mae: 2.1940 - val_loss: 117.4663 - val_mae: 8.5769\n",
      "Epoch 84/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 6.8904 - mae: 2.0232 - val_loss: 121.0746 - val_mae: 8.1139\n",
      "Epoch 85/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 5.7848 - mae: 1.8232 - val_loss: 95.7036 - val_mae: 8.0229\n",
      "Epoch 86/100\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 8.9096 - mae: 2.3307 - val_loss: 117.2823 - val_mae: 8.4440\n",
      "Epoch 87/100\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 8.3207 - mae: 2.3610 - val_loss: 119.9365 - val_mae: 9.4599\n",
      "Epoch 88/100\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 8.3938 - mae: 2.3169 - val_loss: 89.1592 - val_mae: 7.5951\n",
      "Epoch 89/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 7.7754 - mae: 2.2700 - val_loss: 99.8366 - val_mae: 8.7341\n",
      "Epoch 90/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 5.4151 - mae: 1.9323 - val_loss: 86.0654 - val_mae: 7.2364\n",
      "Epoch 91/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 6.9931 - mae: 2.2702 - val_loss: 86.0108 - val_mae: 7.3831\n",
      "Epoch 92/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 8.2846 - mae: 2.3382 - val_loss: 97.4459 - val_mae: 7.4847\n",
      "Epoch 93/100\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 6.8937 - mae: 2.2076 - val_loss: 107.4215 - val_mae: 9.1071\n",
      "Epoch 94/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 7.1208 - mae: 2.0088 - val_loss: 98.1794 - val_mae: 7.2964\n",
      "Epoch 95/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 7.2084 - mae: 2.3888 - val_loss: 105.3305 - val_mae: 8.4823\n",
      "Epoch 96/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 4.8519 - mae: 1.5862 - val_loss: 100.3700 - val_mae: 8.4859\n",
      "Epoch 97/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 8.0186 - mae: 2.2192 - val_loss: 86.7620 - val_mae: 7.2855\n",
      "Epoch 98/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 6.2211 - mae: 1.9773 - val_loss: 117.2476 - val_mae: 8.9449\n",
      "Epoch 99/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 6.9727 - mae: 2.0597 - val_loss: 86.4793 - val_mae: 8.0342\n",
      "Epoch 100/100\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 5.2222 - mae: 1.7198 - val_loss: 97.3473 - val_mae: 7.4377\n",
      "Wall time: 29.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(26,)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='rmsprop', metrics=['mae'])\n",
    "\n",
    "hist = model.fit(X_train, y_train, epochs=100, batch_size=1, validation_data=(X_test, y_test), shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
