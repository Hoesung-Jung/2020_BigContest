{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SB_D</th>\n",
       "      <th>SB_R</th>\n",
       "      <th>ERA</th>\n",
       "      <th>ER</th>\n",
       "      <th>CG</th>\n",
       "      <th>SHO</th>\n",
       "      <th>RA</th>\n",
       "      <th>R</th>\n",
       "      <th>AB</th>\n",
       "      <th>H</th>\n",
       "      <th>...</th>\n",
       "      <th>FP</th>\n",
       "      <th>SV</th>\n",
       "      <th>IPOuts</th>\n",
       "      <th>HA</th>\n",
       "      <th>HRA</th>\n",
       "      <th>BBA</th>\n",
       "      <th>SOA</th>\n",
       "      <th>E</th>\n",
       "      <th>DP</th>\n",
       "      <th>W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124</td>\n",
       "      <td>64</td>\n",
       "      <td>5.76</td>\n",
       "      <td>827</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.32</td>\n",
       "      <td>826</td>\n",
       "      <td>5109</td>\n",
       "      <td>1478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977</td>\n",
       "      <td>24</td>\n",
       "      <td>3878</td>\n",
       "      <td>1520</td>\n",
       "      <td>155</td>\n",
       "      <td>634</td>\n",
       "      <td>976</td>\n",
       "      <td>124</td>\n",
       "      <td>229</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136</td>\n",
       "      <td>101</td>\n",
       "      <td>4.97</td>\n",
       "      <td>705</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5.54</td>\n",
       "      <td>803</td>\n",
       "      <td>4999</td>\n",
       "      <td>1429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979</td>\n",
       "      <td>38</td>\n",
       "      <td>3828</td>\n",
       "      <td>1456</td>\n",
       "      <td>131</td>\n",
       "      <td>561</td>\n",
       "      <td>965</td>\n",
       "      <td>111</td>\n",
       "      <td>219</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>96</td>\n",
       "      <td>5.92</td>\n",
       "      <td>838</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.55</td>\n",
       "      <td>672</td>\n",
       "      <td>4963</td>\n",
       "      <td>1369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976</td>\n",
       "      <td>27</td>\n",
       "      <td>3819</td>\n",
       "      <td>1593</td>\n",
       "      <td>145</td>\n",
       "      <td>560</td>\n",
       "      <td>980</td>\n",
       "      <td>130</td>\n",
       "      <td>264</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>121</td>\n",
       "      <td>5.04</td>\n",
       "      <td>721</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5.64</td>\n",
       "      <td>786</td>\n",
       "      <td>5051</td>\n",
       "      <td>1464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981</td>\n",
       "      <td>34</td>\n",
       "      <td>3863</td>\n",
       "      <td>1426</td>\n",
       "      <td>122</td>\n",
       "      <td>539</td>\n",
       "      <td>909</td>\n",
       "      <td>103</td>\n",
       "      <td>217</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>145</td>\n",
       "      <td>5.63</td>\n",
       "      <td>792</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6.15</td>\n",
       "      <td>777</td>\n",
       "      <td>5001</td>\n",
       "      <td>1439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983</td>\n",
       "      <td>27</td>\n",
       "      <td>3799</td>\n",
       "      <td>1486</td>\n",
       "      <td>161</td>\n",
       "      <td>585</td>\n",
       "      <td>1009</td>\n",
       "      <td>91</td>\n",
       "      <td>229</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SB_D  SB_R   ERA   ER  CG  SHO    RA    R    AB     H  ...     FP  SV  \\\n",
       "0   124    64  5.76  827   1    2  6.32  826  5109  1478  ...  0.977  24   \n",
       "1   136   101  4.97  705   7    5  5.54  803  4999  1429  ...  0.979  38   \n",
       "2   115    96  5.92  838   1    2  6.55  672  4963  1369  ...  0.976  27   \n",
       "3    80   121  5.04  721   2    5  5.64  786  5051  1464  ...  0.981  34   \n",
       "4    90   145  5.63  792   2    5  6.15  777  5001  1439  ...  0.983  27   \n",
       "\n",
       "   IPOuts    HA  HRA  BBA   SOA    E   DP   W  \n",
       "0    3878  1520  155  634   976  124  229  66  \n",
       "1    3828  1456  131  561   965  111  219  70  \n",
       "2    3819  1593  145  560   980  130  264  53  \n",
       "3    3863  1426  122  539   909  103  217  71  \n",
       "4    3799  1486  161  585  1009   91  229  66  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('practice.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(df['W'])\n",
    "plt.xlabel('Wins')\n",
    "plt.title('Distribution of Wins')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SB_D      0.406149\n",
       "SB_R      0.623423\n",
       "ERA      -0.313221\n",
       "ER        0.503294\n",
       "CG        0.209995\n",
       "SHO       0.473576\n",
       "RA       -0.339742\n",
       "R         0.876900\n",
       "AB        0.838537\n",
       "H         0.867653\n",
       "2B        0.818614\n",
       "3B        0.607394\n",
       "HR        0.678608\n",
       "BB        0.627698\n",
       "SO        0.806856\n",
       "Rank     -0.522707\n",
       "G         0.828139\n",
       "FP        0.109302\n",
       "SV        0.922951\n",
       "IPOuts    0.837875\n",
       "HA        0.732641\n",
       "HRA       0.491891\n",
       "BBA       0.627698\n",
       "SOA       0.806856\n",
       "E         0.664863\n",
       "DP        0.259039\n",
       "W         1.000000\n",
       "Name: W, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[124.  ,  64.  ,   5.76, ..., 976.  , 124.  , 229.  ],\n",
       "       [136.  , 101.  ,   4.97, ..., 965.  , 111.  , 219.  ],\n",
       "       [115.  ,  96.  ,   5.92, ..., 980.  , 130.  , 264.  ],\n",
       "       ...,\n",
       "       [ 82.  ,  44.  ,   5.46, ..., 447.  ,  46.  ,  53.  ],\n",
       "       [ 34.  ,  81.  ,   4.61, ..., 401.  ,  43.  ,  57.  ],\n",
       "       [ 54.  ,  65.  ,   4.37, ..., 425.  ,  47.  ,  62.  ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = df.values[:, 0:26]\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66.],\n",
       "       [70.],\n",
       "       [53.],\n",
       "       [71.],\n",
       "       [66.],\n",
       "       [83.],\n",
       "       [93.],\n",
       "       [69.],\n",
       "       [65.],\n",
       "       [77.],\n",
       "       [61.],\n",
       "       [87.],\n",
       "       [50.],\n",
       "       [69.],\n",
       "       [80.],\n",
       "       [79.],\n",
       "       [84.],\n",
       "       [75.],\n",
       "       [55.],\n",
       "       [69.],\n",
       "       [77.],\n",
       "       [70.],\n",
       "       [59.],\n",
       "       [68.],\n",
       "       [68.],\n",
       "       [58.],\n",
       "       [93.],\n",
       "       [78.],\n",
       "       [68.],\n",
       "       [75.],\n",
       "       [58.],\n",
       "       [62.],\n",
       "       [71.],\n",
       "       [79.],\n",
       "       [48.],\n",
       "       [73.],\n",
       "       [88.],\n",
       "       [88.],\n",
       "       [60.],\n",
       "       [86.],\n",
       "       [17.],\n",
       "       [33.],\n",
       "       [31.],\n",
       "       [34.],\n",
       "       [30.],\n",
       "       [42.],\n",
       "       [38.],\n",
       "       [21.],\n",
       "       [34.],\n",
       "       [38.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = df.values[:, [26]]\n",
    "y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = scaler.fit_transform(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45, 26), (45, 1), (5, 26), (5, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.1, random_state=7)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기울기: [[ -0.18236276   0.14671256   8.20986015 -18.69091666  -1.17798803\n",
      "    0.67714682  -2.27818537  18.94768164   6.7835888  -13.71753123\n",
      "    1.41563051  -2.14874987  -1.44882931   1.61061913  -2.10618722\n",
      "   -3.74254544  15.82163502   0.96382358   5.75196783  -6.85763062\n",
      "    8.25212526  -0.76920751   1.61061913  -2.10618722   2.74777861\n",
      "   -1.52243656]]\n",
      "절편: [63.21471165]\n",
      "훈련 정확도:0.99039\n",
      "테스트 정확도:0.92562\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "print(\"기울기:\", lr.coef_)  # [0.39390555]\n",
    "print(\"절편:\", lr.intercept_)  # -0.03180434302675973\n",
    "print(\"훈련 정확도:{:.5f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"테스트 정확도:{:.5f}\".format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45 samples, validate on 5 samples\n",
      "Epoch 1/100\n",
      "45/45 [==============================] - 1s 29ms/step - loss: 2910.6881 - mean_absolute_error: 49.0678 - val_loss: 800.3698 - val_mean_absolute_error: 23.6193\n",
      "Epoch 2/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 308.7848 - mean_absolute_error: 14.3448 - val_loss: 138.3289 - val_mean_absolute_error: 9.3844\n",
      "Epoch 3/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 119.2310 - mean_absolute_error: 8.2921 - val_loss: 111.5233 - val_mean_absolute_error: 8.8046\n",
      "Epoch 4/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 105.6672 - mean_absolute_error: 7.8679 - val_loss: 77.3123 - val_mean_absolute_error: 7.7075\n",
      "Epoch 5/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 90.1861 - mean_absolute_error: 6.1969 - val_loss: 78.1611 - val_mean_absolute_error: 7.1312\n",
      "Epoch 6/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 59.7504 - mean_absolute_error: 5.7789 - val_loss: 78.5451 - val_mean_absolute_error: 7.4512\n",
      "Epoch 7/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 53.6308 - mean_absolute_error: 5.7904 - val_loss: 77.2881 - val_mean_absolute_error: 7.7672\n",
      "Epoch 8/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 45.8724 - mean_absolute_error: 5.0112 - val_loss: 84.1755 - val_mean_absolute_error: 6.7695\n",
      "Epoch 9/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 40.6554 - mean_absolute_error: 4.9040 - val_loss: 45.6986 - val_mean_absolute_error: 4.8145\n",
      "Epoch 10/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 32.6985 - mean_absolute_error: 4.5531 - val_loss: 89.6793 - val_mean_absolute_error: 8.2589\n",
      "Epoch 11/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 29.9505 - mean_absolute_error: 4.4673 - val_loss: 78.0105 - val_mean_absolute_error: 7.4786\n",
      "Epoch 12/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 20.1553 - mean_absolute_error: 3.6839 - val_loss: 49.2488 - val_mean_absolute_error: 6.1587\n",
      "Epoch 13/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 24.1338 - mean_absolute_error: 3.9236 - val_loss: 80.7116 - val_mean_absolute_error: 6.9374\n",
      "Epoch 14/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 23.2368 - mean_absolute_error: 3.7191 - val_loss: 73.9895 - val_mean_absolute_error: 6.6969\n",
      "Epoch 15/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 23.1622 - mean_absolute_error: 3.8497 - val_loss: 81.5695 - val_mean_absolute_error: 6.0511\n",
      "Epoch 16/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 19.2958 - mean_absolute_error: 3.6033 - val_loss: 62.6063 - val_mean_absolute_error: 6.9326\n",
      "Epoch 17/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 18.7950 - mean_absolute_error: 3.6007 - val_loss: 86.3489 - val_mean_absolute_error: 7.3397\n",
      "Epoch 18/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 19.2405 - mean_absolute_error: 3.4631 - val_loss: 80.7769 - val_mean_absolute_error: 6.5224\n",
      "Epoch 19/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 17.0472 - mean_absolute_error: 2.9410 - val_loss: 81.4236 - val_mean_absolute_error: 7.1779\n",
      "Epoch 20/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 15.6371 - mean_absolute_error: 3.1079 - val_loss: 81.9513 - val_mean_absolute_error: 6.8556\n",
      "Epoch 21/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 12.6385 - mean_absolute_error: 2.7230 - val_loss: 103.7057 - val_mean_absolute_error: 8.0208\n",
      "Epoch 22/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 13.3606 - mean_absolute_error: 2.7713 - val_loss: 73.8419 - val_mean_absolute_error: 7.0657\n",
      "Epoch 23/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 15.7803 - mean_absolute_error: 3.2349 - val_loss: 75.0897 - val_mean_absolute_error: 7.7476\n",
      "Epoch 24/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 8.8255 - mean_absolute_error: 2.4824 - val_loss: 117.2099 - val_mean_absolute_error: 9.2842\n",
      "Epoch 25/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 15.3523 - mean_absolute_error: 3.2731 - val_loss: 103.2711 - val_mean_absolute_error: 8.4685\n",
      "Epoch 26/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 12.7013 - mean_absolute_error: 2.9153 - val_loss: 96.5496 - val_mean_absolute_error: 8.0863\n",
      "Epoch 27/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 13.8633 - mean_absolute_error: 2.6485 - val_loss: 84.4815 - val_mean_absolute_error: 6.9075\n",
      "Epoch 28/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 11.0109 - mean_absolute_error: 2.6606 - val_loss: 99.6692 - val_mean_absolute_error: 7.9540\n",
      "Epoch 29/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 16.1816 - mean_absolute_error: 3.0065 - val_loss: 76.4887 - val_mean_absolute_error: 6.6800\n",
      "Epoch 30/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.2564 - mean_absolute_error: 2.3545 - val_loss: 97.5517 - val_mean_absolute_error: 8.1523\n",
      "Epoch 31/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 13.6674 - mean_absolute_error: 3.0059 - val_loss: 85.2530 - val_mean_absolute_error: 7.6704\n",
      "Epoch 32/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.9700 - mean_absolute_error: 2.4098 - val_loss: 112.7484 - val_mean_absolute_error: 8.8922\n",
      "Epoch 33/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 10.3504 - mean_absolute_error: 2.7108 - val_loss: 84.9481 - val_mean_absolute_error: 7.6353\n",
      "Epoch 34/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 10.9848 - mean_absolute_error: 2.6440 - val_loss: 137.9600 - val_mean_absolute_error: 9.7776\n",
      "Epoch 35/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 10.7164 - mean_absolute_error: 2.5190 - val_loss: 133.8172 - val_mean_absolute_error: 9.1098\n",
      "Epoch 36/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 10.6484 - mean_absolute_error: 2.5778 - val_loss: 70.0215 - val_mean_absolute_error: 7.3682\n",
      "Epoch 37/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 10.8950 - mean_absolute_error: 2.8259 - val_loss: 104.1487 - val_mean_absolute_error: 8.3642\n",
      "Epoch 38/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 12.4895 - mean_absolute_error: 2.9694 - val_loss: 113.8423 - val_mean_absolute_error: 8.9572\n",
      "Epoch 39/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 12.4512 - mean_absolute_error: 2.7485 - val_loss: 81.2425 - val_mean_absolute_error: 7.9525\n",
      "Epoch 40/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 9.2565 - mean_absolute_error: 2.1597 - val_loss: 101.9295 - val_mean_absolute_error: 7.7072\n",
      "Epoch 41/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 11.9418 - mean_absolute_error: 2.8246 - val_loss: 115.7674 - val_mean_absolute_error: 9.6427\n",
      "Epoch 42/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 9.5263 - mean_absolute_error: 2.4920 - val_loss: 98.8106 - val_mean_absolute_error: 8.0698\n",
      "Epoch 43/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 9.8667 - mean_absolute_error: 2.5907 - val_loss: 109.6485 - val_mean_absolute_error: 8.6059\n",
      "Epoch 44/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 11.6964 - mean_absolute_error: 2.8711 - val_loss: 77.6142 - val_mean_absolute_error: 7.0458\n",
      "Epoch 45/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 9.7327 - mean_absolute_error: 2.5514 - val_loss: 79.8385 - val_mean_absolute_error: 7.6029\n",
      "Epoch 46/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 11.6280 - mean_absolute_error: 2.9252 - val_loss: 106.0802 - val_mean_absolute_error: 8.7350\n",
      "Epoch 47/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.1609 - mean_absolute_error: 2.4585 - val_loss: 134.0388 - val_mean_absolute_error: 9.8729\n",
      "Epoch 48/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 11.1881 - mean_absolute_error: 2.7822 - val_loss: 56.6125 - val_mean_absolute_error: 6.0844\n",
      "Epoch 49/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 10.6114 - mean_absolute_error: 2.7480 - val_loss: 83.0456 - val_mean_absolute_error: 7.1418\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 2ms/step - loss: 8.9009 - mean_absolute_error: 2.2343 - val_loss: 90.9722 - val_mean_absolute_error: 7.4250\n",
      "Epoch 51/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 11.6691 - mean_absolute_error: 2.6911 - val_loss: 61.2916 - val_mean_absolute_error: 6.0555\n",
      "Epoch 52/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 8.0545 - mean_absolute_error: 2.0716 - val_loss: 81.2724 - val_mean_absolute_error: 7.0502\n",
      "Epoch 53/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 12.5206 - mean_absolute_error: 2.5198 - val_loss: 78.1659 - val_mean_absolute_error: 6.8376\n",
      "Epoch 54/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 10.8982 - mean_absolute_error: 2.5627 - val_loss: 83.2315 - val_mean_absolute_error: 7.8111\n",
      "Epoch 55/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 9.1642 - mean_absolute_error: 2.4015 - val_loss: 94.5726 - val_mean_absolute_error: 7.9261\n",
      "Epoch 56/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 8.3611 - mean_absolute_error: 2.3641 - val_loss: 77.7835 - val_mean_absolute_error: 6.7208\n",
      "Epoch 57/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.1217 - mean_absolute_error: 2.0853 - val_loss: 97.1417 - val_mean_absolute_error: 7.2381\n",
      "Epoch 58/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 10.0569 - mean_absolute_error: 2.6317 - val_loss: 110.2354 - val_mean_absolute_error: 7.8020\n",
      "Epoch 59/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 7.7569 - mean_absolute_error: 2.1770 - val_loss: 108.0812 - val_mean_absolute_error: 8.2623\n",
      "Epoch 60/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 12.4853 - mean_absolute_error: 2.8625 - val_loss: 72.5678 - val_mean_absolute_error: 6.7929\n",
      "Epoch 61/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 7.8087 - mean_absolute_error: 2.2977 - val_loss: 67.0414 - val_mean_absolute_error: 6.4078\n",
      "Epoch 62/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 9.5171 - mean_absolute_error: 2.4923 - val_loss: 93.8494 - val_mean_absolute_error: 7.6697\n",
      "Epoch 63/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.2720 - mean_absolute_error: 2.2412 - val_loss: 101.7148 - val_mean_absolute_error: 8.2825\n",
      "Epoch 64/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 9.0795 - mean_absolute_error: 2.3543 - val_loss: 64.1168 - val_mean_absolute_error: 7.1150\n",
      "Epoch 65/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 10.2465 - mean_absolute_error: 2.5502 - val_loss: 75.9288 - val_mean_absolute_error: 7.6154\n",
      "Epoch 66/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 6.9962 - mean_absolute_error: 2.0576 - val_loss: 95.0048 - val_mean_absolute_error: 6.9872\n",
      "Epoch 67/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 11.5608 - mean_absolute_error: 2.8911 - val_loss: 108.6334 - val_mean_absolute_error: 8.1778\n",
      "Epoch 68/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 5.7692 - mean_absolute_error: 1.7569 - val_loss: 59.0622 - val_mean_absolute_error: 6.3877\n",
      "Epoch 69/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 10.1700 - mean_absolute_error: 2.5490 - val_loss: 84.2635 - val_mean_absolute_error: 7.2058\n",
      "Epoch 70/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 7.9150 - mean_absolute_error: 2.1108 - val_loss: 87.1611 - val_mean_absolute_error: 7.4913\n",
      "Epoch 71/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 10.1412 - mean_absolute_error: 2.4523 - val_loss: 90.8434 - val_mean_absolute_error: 7.5517\n",
      "Epoch 72/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 7.6027 - mean_absolute_error: 2.1493 - val_loss: 80.2768 - val_mean_absolute_error: 7.7657\n",
      "Epoch 73/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 9.6486 - mean_absolute_error: 2.6819 - val_loss: 107.6555 - val_mean_absolute_error: 8.5759\n",
      "Epoch 74/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 7.8345 - mean_absolute_error: 2.1622 - val_loss: 127.4424 - val_mean_absolute_error: 9.0798\n",
      "Epoch 75/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 9.4212 - mean_absolute_error: 2.5348 - val_loss: 88.4907 - val_mean_absolute_error: 8.1570\n",
      "Epoch 76/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.5991 - mean_absolute_error: 2.3984 - val_loss: 106.8595 - val_mean_absolute_error: 8.1329\n",
      "Epoch 77/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.0123 - mean_absolute_error: 2.3257 - val_loss: 118.1936 - val_mean_absolute_error: 8.4743\n",
      "Epoch 78/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.9720 - mean_absolute_error: 2.1672 - val_loss: 79.2784 - val_mean_absolute_error: 6.8995\n",
      "Epoch 79/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 6.3297 - mean_absolute_error: 2.1536 - val_loss: 77.0479 - val_mean_absolute_error: 6.8058\n",
      "Epoch 80/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 12.8459 - mean_absolute_error: 2.8171 - val_loss: 93.2076 - val_mean_absolute_error: 7.0622\n",
      "Epoch 81/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.0309 - mean_absolute_error: 2.2845 - val_loss: 82.7353 - val_mean_absolute_error: 7.3081\n",
      "Epoch 82/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 7.8328 - mean_absolute_error: 2.1613 - val_loss: 94.0034 - val_mean_absolute_error: 8.2584\n",
      "Epoch 83/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 8.4911 - mean_absolute_error: 2.3516 - val_loss: 101.2540 - val_mean_absolute_error: 8.4510\n",
      "Epoch 84/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.1297 - mean_absolute_error: 2.0298 - val_loss: 107.8659 - val_mean_absolute_error: 8.2991\n",
      "Epoch 85/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.5255 - mean_absolute_error: 2.2396 - val_loss: 102.2104 - val_mean_absolute_error: 7.4894\n",
      "Epoch 86/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 9.0101 - mean_absolute_error: 2.3495 - val_loss: 97.8292 - val_mean_absolute_error: 8.2675\n",
      "Epoch 87/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 6.2728 - mean_absolute_error: 1.9086 - val_loss: 93.9269 - val_mean_absolute_error: 7.4156\n",
      "Epoch 88/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 9.7871 - mean_absolute_error: 2.3325 - val_loss: 103.0850 - val_mean_absolute_error: 8.1966\n",
      "Epoch 89/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 6.7372 - mean_absolute_error: 1.9426 - val_loss: 98.7977 - val_mean_absolute_error: 7.7861\n",
      "Epoch 90/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.1159 - mean_absolute_error: 2.1771 - val_loss: 80.4078 - val_mean_absolute_error: 6.7696\n",
      "Epoch 91/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 7.9789 - mean_absolute_error: 2.3231 - val_loss: 99.4937 - val_mean_absolute_error: 8.2996\n",
      "Epoch 92/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 9.7070 - mean_absolute_error: 2.4689 - val_loss: 64.6712 - val_mean_absolute_error: 6.9351\n",
      "Epoch 93/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 6.4932 - mean_absolute_error: 2.0282 - val_loss: 93.8442 - val_mean_absolute_error: 7.9521\n",
      "Epoch 94/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 8.8793 - mean_absolute_error: 2.2043 - val_loss: 72.0200 - val_mean_absolute_error: 6.6075\n",
      "Epoch 95/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 9.6992 - mean_absolute_error: 2.4777 - val_loss: 90.1847 - val_mean_absolute_error: 7.6458\n",
      "Epoch 96/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 5.7763 - mean_absolute_error: 2.0079 - val_loss: 100.4537 - val_mean_absolute_error: 7.8661\n",
      "Epoch 97/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 8.0208 - mean_absolute_error: 2.3117 - val_loss: 94.9000 - val_mean_absolute_error: 8.1790\n",
      "Epoch 98/100\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 6.8655 - mean_absolute_error: 2.0924 - val_loss: 98.4163 - val_mean_absolute_error: 7.8096\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 2ms/step - loss: 8.9208 - mean_absolute_error: 2.5094 - val_loss: 86.9567 - val_mean_absolute_error: 7.7807\n",
      "Epoch 100/100\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 6.6768 - mean_absolute_error: 2.0441 - val_loss: 120.3956 - val_mean_absolute_error: 9.4301\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(26,)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='rmsprop', metrics=['mae'])\n",
    "\n",
    "hist = model.fit(X_train, y_train, epochs=100, batch_size=1, validation_data=(X_test, y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
