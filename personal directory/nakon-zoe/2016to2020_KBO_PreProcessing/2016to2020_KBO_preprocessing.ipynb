{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2016 to 2020: KBO preprocessing _ myPart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SB_D, CS_D, SB_R, CS_R, SF_H, HBP_H, ERA, HBP_P, ER, CG, SHO, SF_P, RA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python warning off\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# tensorflow warning off\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearID</th>\n",
       "      <th>teamID</th>\n",
       "      <th>SB_D</th>\n",
       "      <th>CS_D</th>\n",
       "      <th>SB_R</th>\n",
       "      <th>CS_R</th>\n",
       "      <th>SF_H</th>\n",
       "      <th>HBP_H</th>\n",
       "      <th>ERA</th>\n",
       "      <th>HBP_P</th>\n",
       "      <th>ER</th>\n",
       "      <th>CG</th>\n",
       "      <th>SHO</th>\n",
       "      <th>SF_P</th>\n",
       "      <th>RA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>키움</td>\n",
       "      <td>54</td>\n",
       "      <td>26</td>\n",
       "      <td>65</td>\n",
       "      <td>14</td>\n",
       "      <td>37</td>\n",
       "      <td>46</td>\n",
       "      <td>4.37</td>\n",
       "      <td>48</td>\n",
       "      <td>380</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>4.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>KIA</td>\n",
       "      <td>48</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "      <td>4.48</td>\n",
       "      <td>32</td>\n",
       "      <td>358</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>4.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>LG</td>\n",
       "      <td>47</td>\n",
       "      <td>23</td>\n",
       "      <td>46</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>43</td>\n",
       "      <td>4.59</td>\n",
       "      <td>49</td>\n",
       "      <td>392</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>5.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>삼성</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>81</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>44</td>\n",
       "      <td>4.61</td>\n",
       "      <td>41</td>\n",
       "      <td>382</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>5.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>롯데</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>53</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>35</td>\n",
       "      <td>4.61</td>\n",
       "      <td>29</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   yearID teamID  SB_D  CS_D  SB_R  CS_R  SF_H  HBP_H   ERA  HBP_P   ER  CG  \\\n",
       "0    2020     키움    54    26    65    14    37     46  4.37     48  380   0   \n",
       "1    2020    KIA    48    28    23    10    16     37  4.48     32  358   1   \n",
       "2    2020     LG    47    23    46    26    31     43  4.59     49  392   1   \n",
       "3    2020     삼성    34    22    81    36    31     44  4.61     41  382   2   \n",
       "4    2020     롯데    55    16    53    20    26     35  4.61     29  365   1   \n",
       "\n",
       "   SHO  SF_P    RA  \n",
       "0    2    22  4.76  \n",
       "1    2    25  4.86  \n",
       "2    8    32  5.03  \n",
       "3    9    30  5.22  \n",
       "4    9    34  5.00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('my_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearID</th>\n",
       "      <th>teamID</th>\n",
       "      <th>SB_D</th>\n",
       "      <th>CS_D</th>\n",
       "      <th>SB_R</th>\n",
       "      <th>CS_R</th>\n",
       "      <th>SF_H</th>\n",
       "      <th>HBP_H</th>\n",
       "      <th>ERA</th>\n",
       "      <th>HBP_P</th>\n",
       "      <th>ER</th>\n",
       "      <th>CG</th>\n",
       "      <th>SHO</th>\n",
       "      <th>SF_P</th>\n",
       "      <th>RA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>WO</td>\n",
       "      <td>54</td>\n",
       "      <td>26</td>\n",
       "      <td>65</td>\n",
       "      <td>14</td>\n",
       "      <td>37</td>\n",
       "      <td>46</td>\n",
       "      <td>4.37</td>\n",
       "      <td>48</td>\n",
       "      <td>380</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>4.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>HT</td>\n",
       "      <td>48</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "      <td>4.48</td>\n",
       "      <td>32</td>\n",
       "      <td>358</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>4.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>LG</td>\n",
       "      <td>47</td>\n",
       "      <td>23</td>\n",
       "      <td>46</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>43</td>\n",
       "      <td>4.59</td>\n",
       "      <td>49</td>\n",
       "      <td>392</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>5.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>SS</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>81</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>44</td>\n",
       "      <td>4.61</td>\n",
       "      <td>41</td>\n",
       "      <td>382</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>5.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>LT</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>53</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>35</td>\n",
       "      <td>4.61</td>\n",
       "      <td>29</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   yearID teamID  SB_D  CS_D  SB_R  CS_R  SF_H  HBP_H   ERA  HBP_P   ER  CG  \\\n",
       "0    2020     WO    54    26    65    14    37     46  4.37     48  380   0   \n",
       "1    2020     HT    48    28    23    10    16     37  4.48     32  358   1   \n",
       "2    2020     LG    47    23    46    26    31     43  4.59     49  392   1   \n",
       "3    2020     SS    34    22    81    36    31     44  4.61     41  382   2   \n",
       "4    2020     LT    55    16    53    20    26     35  4.61     29  365   1   \n",
       "\n",
       "   SHO  SF_P    RA  \n",
       "0    2    22  4.76  \n",
       "1    2    25  4.86  \n",
       "2    8    32  5.03  \n",
       "3    9    30  5.22  \n",
       "4    9    34  5.00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    if df['teamID'][i]=='두산':\n",
    "        df['teamID'][i]='OB'\n",
    "    elif df['teamID'][i]=='키움' or df['teamID'][i]=='넥센':\n",
    "        df['teamID'][i]='WO'\n",
    "    elif df['teamID'][i]=='KIA':\n",
    "        df['teamID'][i]='HT'\n",
    "    elif df['teamID'][i]=='삼성':\n",
    "        df['teamID'][i]='SS'\n",
    "    elif df['teamID'][i]=='롯데':\n",
    "        df['teamID'][i]='LT'\n",
    "    elif df['teamID'][i]=='한화':\n",
    "        df['teamID'][i]='HH'\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearID</th>\n",
       "      <th>teamID</th>\n",
       "      <th>SB_D</th>\n",
       "      <th>CS_D</th>\n",
       "      <th>SB_R</th>\n",
       "      <th>CS_R</th>\n",
       "      <th>SF_H</th>\n",
       "      <th>HBP_H</th>\n",
       "      <th>ERA</th>\n",
       "      <th>HBP_P</th>\n",
       "      <th>ER</th>\n",
       "      <th>CG</th>\n",
       "      <th>SHO</th>\n",
       "      <th>SF_P</th>\n",
       "      <th>RA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>124</td>\n",
       "      <td>66</td>\n",
       "      <td>64</td>\n",
       "      <td>38</td>\n",
       "      <td>41</td>\n",
       "      <td>91</td>\n",
       "      <td>5.76</td>\n",
       "      <td>76</td>\n",
       "      <td>827</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>6.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>2016</td>\n",
       "      <td>HT</td>\n",
       "      <td>136</td>\n",
       "      <td>49</td>\n",
       "      <td>101</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>87</td>\n",
       "      <td>4.97</td>\n",
       "      <td>59</td>\n",
       "      <td>705</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>5.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>2016</td>\n",
       "      <td>KT</td>\n",
       "      <td>115</td>\n",
       "      <td>55</td>\n",
       "      <td>96</td>\n",
       "      <td>46</td>\n",
       "      <td>45</td>\n",
       "      <td>48</td>\n",
       "      <td>5.92</td>\n",
       "      <td>84</td>\n",
       "      <td>838</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>6.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>80</td>\n",
       "      <td>49</td>\n",
       "      <td>121</td>\n",
       "      <td>70</td>\n",
       "      <td>54</td>\n",
       "      <td>72</td>\n",
       "      <td>5.04</td>\n",
       "      <td>109</td>\n",
       "      <td>721</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>2016</td>\n",
       "      <td>LT</td>\n",
       "      <td>90</td>\n",
       "      <td>59</td>\n",
       "      <td>145</td>\n",
       "      <td>64</td>\n",
       "      <td>41</td>\n",
       "      <td>83</td>\n",
       "      <td>5.63</td>\n",
       "      <td>78</td>\n",
       "      <td>792</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>6.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    yearID teamID  SB_D  CS_D  SB_R  CS_R  SF_H  HBP_H   ERA  HBP_P   ER  CG  \\\n",
       "40    2016     HH   124    66    64    38    41     91  5.76     76  827   1   \n",
       "46    2016     HT   136    49   101    50    45     87  4.97     59  705   7   \n",
       "48    2016     KT   115    55    96    46    45     48  5.92     84  838   1   \n",
       "42    2016     LG    80    49   121    70    54     72  5.04    109  721   2   \n",
       "49    2016     LT    90    59   145    64    41     83  5.63     78  792   2   \n",
       "\n",
       "    SHO  SF_P    RA  \n",
       "40    2    59  6.32  \n",
       "46    5    54  5.54  \n",
       "48    2    45  6.55  \n",
       "42    5    56  5.64  \n",
       "49    5    52  6.15  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values(by=['yearID', 'teamID'], ascending=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('nakon.csv', index = False, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearID</th>\n",
       "      <th>teamID</th>\n",
       "      <th>franchID</th>\n",
       "      <th>SB_D</th>\n",
       "      <th>CS_D</th>\n",
       "      <th>SB_R</th>\n",
       "      <th>CS_R</th>\n",
       "      <th>SF_H</th>\n",
       "      <th>HBP_H</th>\n",
       "      <th>ERA</th>\n",
       "      <th>...</th>\n",
       "      <th>PPF</th>\n",
       "      <th>SV</th>\n",
       "      <th>IPOuts</th>\n",
       "      <th>HA</th>\n",
       "      <th>HRA</th>\n",
       "      <th>BBA</th>\n",
       "      <th>SOA</th>\n",
       "      <th>E</th>\n",
       "      <th>DP</th>\n",
       "      <th>W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>DJ</td>\n",
       "      <td>124</td>\n",
       "      <td>66</td>\n",
       "      <td>64</td>\n",
       "      <td>38</td>\n",
       "      <td>41</td>\n",
       "      <td>91</td>\n",
       "      <td>5.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998399</td>\n",
       "      <td>24</td>\n",
       "      <td>3878</td>\n",
       "      <td>1520</td>\n",
       "      <td>155</td>\n",
       "      <td>634</td>\n",
       "      <td>976</td>\n",
       "      <td>124</td>\n",
       "      <td>229</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>HT</td>\n",
       "      <td>GJ</td>\n",
       "      <td>136</td>\n",
       "      <td>49</td>\n",
       "      <td>101</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>87</td>\n",
       "      <td>4.97</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966443</td>\n",
       "      <td>38</td>\n",
       "      <td>3828</td>\n",
       "      <td>1456</td>\n",
       "      <td>131</td>\n",
       "      <td>561</td>\n",
       "      <td>965</td>\n",
       "      <td>111</td>\n",
       "      <td>219</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>KT</td>\n",
       "      <td>SW</td>\n",
       "      <td>115</td>\n",
       "      <td>55</td>\n",
       "      <td>96</td>\n",
       "      <td>46</td>\n",
       "      <td>45</td>\n",
       "      <td>48</td>\n",
       "      <td>5.92</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006298</td>\n",
       "      <td>27</td>\n",
       "      <td>3819</td>\n",
       "      <td>1593</td>\n",
       "      <td>145</td>\n",
       "      <td>560</td>\n",
       "      <td>980</td>\n",
       "      <td>130</td>\n",
       "      <td>264</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>SO</td>\n",
       "      <td>80</td>\n",
       "      <td>49</td>\n",
       "      <td>121</td>\n",
       "      <td>70</td>\n",
       "      <td>54</td>\n",
       "      <td>72</td>\n",
       "      <td>5.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984622</td>\n",
       "      <td>34</td>\n",
       "      <td>3863</td>\n",
       "      <td>1426</td>\n",
       "      <td>122</td>\n",
       "      <td>539</td>\n",
       "      <td>909</td>\n",
       "      <td>103</td>\n",
       "      <td>217</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>LT</td>\n",
       "      <td>BS</td>\n",
       "      <td>90</td>\n",
       "      <td>59</td>\n",
       "      <td>145</td>\n",
       "      <td>64</td>\n",
       "      <td>41</td>\n",
       "      <td>83</td>\n",
       "      <td>5.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987212</td>\n",
       "      <td>27</td>\n",
       "      <td>3799</td>\n",
       "      <td>1486</td>\n",
       "      <td>161</td>\n",
       "      <td>585</td>\n",
       "      <td>1009</td>\n",
       "      <td>91</td>\n",
       "      <td>229</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   yearID teamID franchID  SB_D  CS_D  SB_R  CS_R  SF_H  HBP_H   ERA  ...  \\\n",
       "0    2016     HH       DJ   124    66    64    38    41     91  5.76  ...   \n",
       "1    2016     HT       GJ   136    49   101    50    45     87  4.97  ...   \n",
       "2    2016     KT       SW   115    55    96    46    45     48  5.92  ...   \n",
       "3    2016     LG       SO    80    49   121    70    54     72  5.04  ...   \n",
       "4    2016     LT       BS    90    59   145    64    41     83  5.63  ...   \n",
       "\n",
       "        PPF  SV  IPOuts    HA  HRA  BBA   SOA    E   DP   W  \n",
       "0  0.998399  24    3878  1520  155  634   976  124  229  66  \n",
       "1  0.966443  38    3828  1456  131  561   965  111  219  70  \n",
       "2  1.006298  27    3819  1593  145  560   980  130  264  53  \n",
       "3  0.984622  34    3863  1426  122  539   909  103  217  71  \n",
       "4  0.987212  27    3799  1486  161  585  1009   91  229  66  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('kbo_data_2016to2020.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SB_D</th>\n",
       "      <th>CS_D</th>\n",
       "      <th>SB_R</th>\n",
       "      <th>CS_R</th>\n",
       "      <th>SF_H</th>\n",
       "      <th>HBP_H</th>\n",
       "      <th>ERA</th>\n",
       "      <th>HBP_P</th>\n",
       "      <th>ER</th>\n",
       "      <th>CG</th>\n",
       "      <th>...</th>\n",
       "      <th>PPF</th>\n",
       "      <th>SV</th>\n",
       "      <th>IPOuts</th>\n",
       "      <th>HA</th>\n",
       "      <th>HRA</th>\n",
       "      <th>BBA</th>\n",
       "      <th>SOA</th>\n",
       "      <th>E</th>\n",
       "      <th>DP</th>\n",
       "      <th>W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>66</td>\n",
       "      <td>64</td>\n",
       "      <td>38</td>\n",
       "      <td>41</td>\n",
       "      <td>91</td>\n",
       "      <td>5.76</td>\n",
       "      <td>76</td>\n",
       "      <td>827</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998399</td>\n",
       "      <td>24</td>\n",
       "      <td>3878</td>\n",
       "      <td>1520</td>\n",
       "      <td>155</td>\n",
       "      <td>634</td>\n",
       "      <td>976</td>\n",
       "      <td>124</td>\n",
       "      <td>229</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>49</td>\n",
       "      <td>101</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>87</td>\n",
       "      <td>4.97</td>\n",
       "      <td>59</td>\n",
       "      <td>705</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966443</td>\n",
       "      <td>38</td>\n",
       "      <td>3828</td>\n",
       "      <td>1456</td>\n",
       "      <td>131</td>\n",
       "      <td>561</td>\n",
       "      <td>965</td>\n",
       "      <td>111</td>\n",
       "      <td>219</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "      <td>55</td>\n",
       "      <td>96</td>\n",
       "      <td>46</td>\n",
       "      <td>45</td>\n",
       "      <td>48</td>\n",
       "      <td>5.92</td>\n",
       "      <td>84</td>\n",
       "      <td>838</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006298</td>\n",
       "      <td>27</td>\n",
       "      <td>3819</td>\n",
       "      <td>1593</td>\n",
       "      <td>145</td>\n",
       "      <td>560</td>\n",
       "      <td>980</td>\n",
       "      <td>130</td>\n",
       "      <td>264</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>49</td>\n",
       "      <td>121</td>\n",
       "      <td>70</td>\n",
       "      <td>54</td>\n",
       "      <td>72</td>\n",
       "      <td>5.04</td>\n",
       "      <td>109</td>\n",
       "      <td>721</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984622</td>\n",
       "      <td>34</td>\n",
       "      <td>3863</td>\n",
       "      <td>1426</td>\n",
       "      <td>122</td>\n",
       "      <td>539</td>\n",
       "      <td>909</td>\n",
       "      <td>103</td>\n",
       "      <td>217</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>59</td>\n",
       "      <td>145</td>\n",
       "      <td>64</td>\n",
       "      <td>41</td>\n",
       "      <td>83</td>\n",
       "      <td>5.63</td>\n",
       "      <td>78</td>\n",
       "      <td>792</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987212</td>\n",
       "      <td>27</td>\n",
       "      <td>3799</td>\n",
       "      <td>1486</td>\n",
       "      <td>161</td>\n",
       "      <td>585</td>\n",
       "      <td>1009</td>\n",
       "      <td>91</td>\n",
       "      <td>229</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SB_D  CS_D  SB_R  CS_R  SF_H  HBP_H   ERA  HBP_P   ER  CG  ...       PPF  \\\n",
       "0   124    66    64    38    41     91  5.76     76  827   1  ...  0.998399   \n",
       "1   136    49   101    50    45     87  4.97     59  705   7  ...  0.966443   \n",
       "2   115    55    96    46    45     48  5.92     84  838   1  ...  1.006298   \n",
       "3    80    49   121    70    54     72  5.04    109  721   2  ...  0.984622   \n",
       "4    90    59   145    64    41     83  5.63     78  792   2  ...  0.987212   \n",
       "\n",
       "   SV  IPOuts    HA  HRA  BBA   SOA    E   DP   W  \n",
       "0  24    3878  1520  155  634   976  124  229  66  \n",
       "1  38    3828  1456  131  561   965  111  219  70  \n",
       "2  27    3819  1593  145  560   980  130  264  53  \n",
       "3  34    3863  1426  122  539   909  103  217  71  \n",
       "4  27    3799  1486  161  585  1009   91  229  66  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df['yearID']; del df['teamID']; del df['franchID']; del df['Attendence']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEWCAYAAAB/tMx4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAATRklEQVR4nO3de7SldV3H8fdHRqURFWiOxm0YSBZJFJfGUlA00EIlbbVMcamBWZMrUzRaBnnPLthFLbstFiqmhhZSEq4QRBEEGppBkMGRMMBxBJlBLgLeQL/98TwHNsczcy57M3v/xvdrrbPOfn772b/nO3vv85nf/u3nkqpCktSeh427AEnS4hjgktQoA1ySGmWAS1KjDHBJapQBLkmNMsA1tCT/lORNI+preZK7k+zQL1+Y5LdG0Xff338lOW5U/S1gu3+S5NYkXx9BXy9Jct4o6lLbDHBtVZIbk3w7yV1J7khyaZJXJrn/vVNVr6yqt8+zr2dubZ2q2lBVO1XV90dQ+1uTfGhG/8+uqg8M2/cC69gLOBE4oKp+Ypb7r03ywoHlw5PULG13J1lSVR+uql/aNtVrkhngmo9fqapHA3sDpwB/CLx31BtJsmTUfU6IvYFvVNWmLdx/EfD0geUjgC/N0nZpVd330JSoFhngmrequrOqzgZeBByX5ECAJKcn+ZP+9rIk5/Sj9duSXJzkYUk+CCwH/rMfSb4+yYp+pPmKJBuATw+0DYb5Tya5PMmdST6eZNd+W89IsnGwxulRfpKjgT8CXtRv76r+/vunZPq63pjkK0k2JfnnJI/t75uu47gkG/rpjzds6blJ8tj+8Zv7/t7Y9/9M4Hxg976O02d5+EV0AT3tacA7Zmm7qN/W8Uk+N7Dt6j8VXZfk9iR/nyT9fU9I8tn+ubs1yUe39G9QewxwLVhVXQ5spAuVmU7s75sCHk8XolVVLwM20I3md6qqvxh4zNOBJwK/vIVN/gbwm8DuwH3A386jxnOBPwM+2m/voFlWO77/+UVgX2An4O9mrPNUYH/gKODNSZ64hU2+B3hs38/T+5pfXlWfAp4N3NTXcfwsj/0s8NNJdu2nplYCHwV2Hmg7jD7At+AY4EnAQcALeeC5fDtwHrALsGdfp7YTBrgW6yZg11na7wV2A/auqnur6uKa+4Q7b62qe6rq21u4/4NVta6q7gHeBLxw+kvOIb0EeGdVXV9VdwMnA8fOGP2/raq+XVVXAVfRBeSD9LW8CDi5qu6qqhuBvwZeNp8iqmoD3X9uT+v7v65/Li4ZaNsRWL2Vbk6pqjv6vj4DHNy330s3hbN7VX2nqj63xR7UHANci7UHcNss7X8JfBk4L8n1SU6aR19fXcD9XwEeDiybV5Vbt3vf32DfS+g+OUwb3GvkW3Sj9JmWAY+Ypa89FlDL9DTKEcDFfdvnBtpWV9V3t/L4LdX5eiDA5UmuSfKbC6hJE84A14IleRJdOP3QaK4fgZ5YVfsCvwL8fpKjpu/eQpdzjdD3Gri9nG5UeStwD7B0oK4d6KZu5tvvTXSj08G+7wNumeNxM93KAyPdwb6+toA+pgP8aTwQ4BcPtG1t+mSLqurrVfXbVbU78DvAPyR5wmL60uQxwDVvSR6T5BjgI8CHqurqWdY5pv/iLMA3ge/3P9AF476L2PRLkxyQZCnwx8CZ/W6G/wvsmOS5SR4OvBF45MDjbgFWDO7yOMMZwOuS7JNkJx6YM1/Qnh59Lf8K/GmSRyfZG/h94ENbf+SDXAQcQjd/fknfdjWwD90c/aICPMmvJ9mzX7yd7j+1oXfR1GQwwDUf/5nkLrqpjDcA7wRevoV19wM+BdwNXAb8Q1Vd2N/358Ab+z1U/mAB2/8gcDrdNMGOwGug2ysG+F3gNLrR7j10X6BO+7f+9zeSXDFLv+/r+74IuAH4DvDqBdQ16NX99q+n+2TyL33/81JV/wtsAm6uqjv6th8AlwOPAS5dZF1PAlYnuRs4Gzihqm5YZF+aMPGCDpLUJkfgktQoA1ySGmWAS1KjDHBJatQ2PXnQsmXLasWKFdtyk5LUvLVr195aVVMz27dpgK9YsYI1a9Zsy01KUvOSfGW2dqdQJKlRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUdv0SExJP2zFSZ8Yy3ZvPOW5Y9muRscRuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElq1JwBnuR9STYlWTfQtmuS85Nc1//e5aEtU5I003xG4KcDR89oOwm4oKr2Ay7olyVJ29CcAV5VFwG3zWh+PvCB/vYHgF8dcV2SpDksdg788VV1M0D/+3GjK0mSNB8P+ZeYSVYlWZNkzebNmx/qzUnSj4zFBvgtSXYD6H9v2tKKVXVqVa2sqpVTU1OL3JwkaabFBvjZwHH97eOAj4+mHEnSfM1nN8IzgMuA/ZNsTPIK4BTgWUmuA57VL0uStqElc61QVS/ewl1HjbgWSdICeCSmJDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjhgrwJK9Lck2SdUnOSLLjqAqTJG3dogM8yR7Aa4CVVXUgsANw7KgKkyRt3bBTKEuAH0uyBFgK3DR8SZKk+Vh0gFfV14C/AjYANwN3VtV5M9dLsirJmiRrNm/evPhKJUkPMswUyi7A84F9gN2BRyV56cz1qurUqlpZVSunpqYWX6kk6UGGmUJ5JnBDVW2uqnuBs4DDRlOWJGkuwwT4BuDJSZYmCXAUsH40ZUmS5jLMHPhq4EzgCuDqvq9TR1SXJGkOS4Z5cFW9BXjLiGqRJC2AR2JKUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1aqizEUrbixUnfWLcJWxz4/w333jKc8e27e2JI3BJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaNVSAJ9k5yZlJvpRkfZKnjKowSdLWDXtBh78Bzq2qFyR5BLB0BDVJkuZh0QGe5DHAEcDxAFX1PeB7oylLkjSXYUbg+wKbgfcnOQhYC5xQVfcMrpRkFbAKYPny5UNsTtL24kftEnYP1SXkhpkDXwIcCvxjVR0C3AOcNHOlqjq1qlZW1cqpqakhNidJGjRMgG8ENlbV6n75TLpAlyRtA4sO8Kr6OvDVJPv3TUcBXxxJVZKkOQ27F8qrgQ/3e6BcD7x8+JIkSfMxVIBX1ZXAyhHVIklaAI/ElKRGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJatSwp5PVQ2hcl516qC7/JGm0HIFLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYNHeBJdkjy+STnjKIgSdL8jGIEfgKwfgT9SJIWYKgAT7In8FzgtNGUI0mar2FH4O8GXg/8YEsrJFmVZE2SNZs3bx5yc5KkaYsO8CTHAJuqau3W1quqU6tqZVWtnJqaWuzmJEkzDDMCPxx4XpIbgY8ARyb50EiqkiTNadEBXlUnV9WeVbUCOBb4dFW9dGSVSZK2yv3AJalRS0bRSVVdCFw4ir4kSfPjCFySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRIzkboTQqK076xLhLkJrhCFySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGLTrAk+yV5DNJ1ie5JskJoyxMkrR1w1zQ4T7gxKq6IsmjgbVJzq+qL46oNknSVix6BF5VN1fVFf3tu4D1wB6jKkyStHUjuaRakhXAIcDqWe5bBawCWL58+aK34aW2JOnBhv4SM8lOwMeA11bVN2feX1WnVtXKqlo5NTU17OYkSb2hAjzJw+nC+8NVddZoSpIkzccwe6EEeC+wvqreObqSJEnzMcwI/HDgZcCRSa7sf54zorokSXNY9JeYVfU5ICOsRZK0AB6JKUmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1KiRXFJN2xcvXye1wRG4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjRoqwJMcneTaJF9OctKoipIkzW3RAZ5kB+DvgWcDBwAvTnLAqAqTJG3dMCPwnwe+XFXXV9X3gI8Azx9NWZKkuQxzSbU9gK8OLG8EfmHmSklWAav6xbuTXDvENhdiGXDrNtrWYljfcKxvONY3nAXVl3cMvb29Z2scJsAzS1v9UEPVqcCpQ2xnUZKsqaqV23q782V9w7G+4VjfcCalvmGmUDYCew0s7wncNFw5kqT5GibA/wfYL8k+SR4BHAucPZqyJElzWfQUSlXdl+T3gE8COwDvq6prRlbZ8Lb5tM0CWd9wrG841jeciagvVT80bS1JaoBHYkpSowxwSWpU8wGeZK8kn0myPsk1SU7o23dNcn6S6/rfu4yxxh2TXJ7kqr7Gt/Xt+yRZ3df40f7L4HHVuEOSzyc5Z9Jq6+u5McnVSa5MsqZvm6TXeOckZyb5Uv9efMqk1Jdk//55m/75ZpLXTkp9fY2v6/821iU5o/+bmZj3YJIT+tquSfLavm3sz1/zAQ7cB5xYVU8Engy8qj+k/yTggqraD7igXx6X7wJHVtVBwMHA0UmeDLwDeFdf4+3AK8ZY4wnA+oHlSapt2i9W1cED+99O0mv8N8C5VfVTwEF0z+VE1FdV1/bP28HAzwHfAv59UupLsgfwGmBlVR1It1PEsUzIezDJgcBv0x19fhBwTJL9mITnr6q2qx/g48CzgGuB3fq23YBrx11bX8tS4Aq6o1ZvBZb07U8BPjmmmvakewMeCZxDd5DWRNQ2UOONwLIZbRPxGgOPAW6g3ylg0uqbUdMvAZdMUn08cFT3rnR7xp0D/PKkvAeBXwdOG1h+E/D6SXj+tocR+P2SrAAOAVYDj6+qmwH6348bX2X3T1FcCWwCzgf+D7ijqu7rV9lI90Yeh3fTvSF/0C//OJNT27QCzkuytj89A0zOa7wvsBl4fz8NdVqSR01QfYOOBc7ob09EfVX1NeCvgA3AzcCdwFom5z24DjgiyY8nWQo8h+4gxrE/f9tNgCfZCfgY8Nqq+ua465mpqr5f3UfYPek+ij1xttW2bVWQ5BhgU1WtHWyeZdVx7296eFUdSnf2y1clOWLM9QxaAhwK/GNVHQLcw3inc2bVzyE/D/i3cdcyqJ87fj6wD7A78Ci613mmsbwHq2o93XTO+cC5wFV0U7djt10EeJKH04X3h6vqrL75liS79ffvRjfyHbuqugO4kG6+fuck0wdTjetUBIcDz0tyI90ZJY+kG5FPQm33q6qb+t+b6OZvf57JeY03AhuranW/fCZdoE9KfdOeDVxRVbf0y5NS3zOBG6pqc1XdC5wFHMYEvQer6r1VdWhVHQHcBlzHBDx/zQd4kgDvBdZX1TsH7jobOK6/fRzd3PhYJJlKsnN/+8fo3rDrgc8AL+hXG0uNVXVyVe1ZVSvoPl5/uqpeMgm1TUvyqCSPnr5NN4+7jgl5javq68BXk+zfNx0FfJEJqW/Ai3lg+gQmp74NwJOTLO3/nqefv0l6Dz6u/70c+DW653H8z984vhQY8RcMT6X7aPUF4Mr+5zl087gX0P1PeQGw6xhr/Fng832N64A39+37ApcDX6b7WPvIMT+XzwDOmbTa+lqu6n+uAd7Qt0/Sa3wwsKZ/jf8D2GXC6lsKfAN47EDbJNX3NuBL/d/HB4FHTth78GK6/1SuAo6alOfPQ+klqVHNT6FI0o8qA1ySGmWAS1KjDHBJapQBLkmNMsC1XUryrumzxvXLn0xy2sDyXyf5oyRnjqdCaXgGuLZXl9IdzUeShwHLgJ8euP8wujPJvWCWx0pNMMC1vbqEPsDpgnsdcFeSXZI8ku5cNLcnWQeQ5PgkZyU5tz+/81/07TskOb0/F/TVSV43jn+MNJtFX9RYmmRVdVOS+/pDnw8DLqM7m91T6M529wXgezMedjDd2Sy/C1yb5D10Z5jbo7rzVDN9SgRpEjgC1/ZsehQ+HeCXDSxfOsv6F1TVnVX1HbrDpvcGrgf2TfKeJEcDE3emS/3oMsC1PZueB/8ZuimU/6YbgR9GF+4zfXfg9vfpLiZwO91VWC4EXgWcNsvjpLEwwLU9uwQ4BrituvOx3wbsTBfil82ngyTLgIdV1cforsRy6ENVrLRQzoFre3Y13d4n/zKjbaequrW/CMhc9qC70s70YOfkEdcoLZpnI5SkRjmFIkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSo/4fZi5VfFCX0tcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(df['W'])\n",
    "plt.xlabel('Wins')\n",
    "plt.title('Distribution of Wins')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SB_D      0.406149\n",
       "CS_D      0.529934\n",
       "SB_R      0.623423\n",
       "CS_R      0.453063\n",
       "SF_H      0.689744\n",
       "HBP_H     0.750313\n",
       "ERA      -0.313221\n",
       "HBP_P     0.577222\n",
       "ER        0.503294\n",
       "CG        0.209995\n",
       "SHO       0.473576\n",
       "SF_P      0.445842\n",
       "RA       -0.339742\n",
       "WSWin     0.358642\n",
       "R         0.876900\n",
       "AB        0.838537\n",
       "H         0.867653\n",
       "2B        0.818614\n",
       "3B        0.607394\n",
       "HR        0.678608\n",
       "BB        0.627698\n",
       "SO        0.806856\n",
       "Rank     -0.522707\n",
       "G         0.828139\n",
       "Ghome     0.828230\n",
       "L         0.376479\n",
       "D         0.232757\n",
       "FP        0.109302\n",
       "BPF      -0.033248\n",
       "PPF      -0.173976\n",
       "SV        0.922951\n",
       "IPOuts    0.837875\n",
       "HA        0.732641\n",
       "HRA       0.491891\n",
       "BBA       0.627698\n",
       "SOA       0.806856\n",
       "E         0.664863\n",
       "DP        0.259039\n",
       "W         1.000000\n",
       "Name: W, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SB_D</th>\n",
       "      <th>CS_D</th>\n",
       "      <th>SB_R</th>\n",
       "      <th>CS_R</th>\n",
       "      <th>SF_H</th>\n",
       "      <th>HBP_H</th>\n",
       "      <th>ERA</th>\n",
       "      <th>HBP_P</th>\n",
       "      <th>ER</th>\n",
       "      <th>CG</th>\n",
       "      <th>...</th>\n",
       "      <th>D</th>\n",
       "      <th>SV</th>\n",
       "      <th>IPOuts</th>\n",
       "      <th>HA</th>\n",
       "      <th>HRA</th>\n",
       "      <th>BBA</th>\n",
       "      <th>SOA</th>\n",
       "      <th>E</th>\n",
       "      <th>DP</th>\n",
       "      <th>W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>66</td>\n",
       "      <td>64</td>\n",
       "      <td>38</td>\n",
       "      <td>41</td>\n",
       "      <td>91</td>\n",
       "      <td>5.76</td>\n",
       "      <td>76</td>\n",
       "      <td>827</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>3878</td>\n",
       "      <td>1520</td>\n",
       "      <td>155</td>\n",
       "      <td>634</td>\n",
       "      <td>976</td>\n",
       "      <td>124</td>\n",
       "      <td>229</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>49</td>\n",
       "      <td>101</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>87</td>\n",
       "      <td>4.97</td>\n",
       "      <td>59</td>\n",
       "      <td>705</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>3828</td>\n",
       "      <td>1456</td>\n",
       "      <td>131</td>\n",
       "      <td>561</td>\n",
       "      <td>965</td>\n",
       "      <td>111</td>\n",
       "      <td>219</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "      <td>55</td>\n",
       "      <td>96</td>\n",
       "      <td>46</td>\n",
       "      <td>45</td>\n",
       "      <td>48</td>\n",
       "      <td>5.92</td>\n",
       "      <td>84</td>\n",
       "      <td>838</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>3819</td>\n",
       "      <td>1593</td>\n",
       "      <td>145</td>\n",
       "      <td>560</td>\n",
       "      <td>980</td>\n",
       "      <td>130</td>\n",
       "      <td>264</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>49</td>\n",
       "      <td>121</td>\n",
       "      <td>70</td>\n",
       "      <td>54</td>\n",
       "      <td>72</td>\n",
       "      <td>5.04</td>\n",
       "      <td>109</td>\n",
       "      <td>721</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>3863</td>\n",
       "      <td>1426</td>\n",
       "      <td>122</td>\n",
       "      <td>539</td>\n",
       "      <td>909</td>\n",
       "      <td>103</td>\n",
       "      <td>217</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>59</td>\n",
       "      <td>145</td>\n",
       "      <td>64</td>\n",
       "      <td>41</td>\n",
       "      <td>83</td>\n",
       "      <td>5.63</td>\n",
       "      <td>78</td>\n",
       "      <td>792</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>3799</td>\n",
       "      <td>1486</td>\n",
       "      <td>161</td>\n",
       "      <td>585</td>\n",
       "      <td>1009</td>\n",
       "      <td>91</td>\n",
       "      <td>229</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SB_D  CS_D  SB_R  CS_R  SF_H  HBP_H   ERA  HBP_P   ER  CG  ...  D  SV  \\\n",
       "0   124    66    64    38    41     91  5.76     76  827   1  ...  3  24   \n",
       "1   136    49   101    50    45     87  4.97     59  705   7  ...  1  38   \n",
       "2   115    55    96    46    45     48  5.92     84  838   1  ...  2  27   \n",
       "3    80    49   121    70    54     72  5.04    109  721   2  ...  2  34   \n",
       "4    90    59   145    64    41     83  5.63     78  792   2  ...  0  27   \n",
       "\n",
       "   IPOuts    HA  HRA  BBA   SOA    E   DP   W  \n",
       "0    3878  1520  155  634   976  124  229  66  \n",
       "1    3828  1456  131  561   965  111  219  70  \n",
       "2    3819  1593  145  560   980  130  264  53  \n",
       "3    3863  1426  122  539   909  103  217  71  \n",
       "4    3799  1486  161  585  1009   91  229  66  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df['FP']; del df['BPF']; del df['PPF']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[124.,  66.,  64., ..., 976., 124., 229.],\n",
       "       [136.,  49., 101., ..., 965., 111., 219.],\n",
       "       [115.,  55.,  96., ..., 980., 130., 264.],\n",
       "       ...,\n",
       "       [ 82.,  31.,  44., ..., 447.,  46.,  53.],\n",
       "       [ 34.,  22.,  81., ..., 401.,  43.,  57.],\n",
       "       [ 54.,  26.,  65., ..., 425.,  47.,  62.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = df.values[:, 0:35]\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66.],\n",
       "       [70.],\n",
       "       [53.],\n",
       "       [71.],\n",
       "       [66.],\n",
       "       [83.],\n",
       "       [93.],\n",
       "       [69.],\n",
       "       [65.],\n",
       "       [77.],\n",
       "       [61.],\n",
       "       [87.],\n",
       "       [50.],\n",
       "       [69.],\n",
       "       [80.],\n",
       "       [79.],\n",
       "       [84.],\n",
       "       [75.],\n",
       "       [55.],\n",
       "       [69.],\n",
       "       [77.],\n",
       "       [70.],\n",
       "       [59.],\n",
       "       [68.],\n",
       "       [68.],\n",
       "       [58.],\n",
       "       [93.],\n",
       "       [78.],\n",
       "       [68.],\n",
       "       [75.],\n",
       "       [58.],\n",
       "       [62.],\n",
       "       [71.],\n",
       "       [79.],\n",
       "       [48.],\n",
       "       [73.],\n",
       "       [88.],\n",
       "       [88.],\n",
       "       [60.],\n",
       "       [86.],\n",
       "       [17.],\n",
       "       [33.],\n",
       "       [31.],\n",
       "       [34.],\n",
       "       [30.],\n",
       "       [42.],\n",
       "       [38.],\n",
       "       [21.],\n",
       "       [34.],\n",
       "       [38.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = df.values[:, [35]]  # 1:survived\n",
    "y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = scaler.fit_transform(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45, 35), (45, 1), (5, 35), (5, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.1, random_state=7)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45 samples, validate on 5 samples\n",
      "Epoch 1/500\n",
      "45/45 [==============================] - 1s 25ms/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "45/45 [==============================] - 0s 620us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "45/45 [==============================] - 0s 576us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "45/45 [==============================] - 0s 444us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/500\n",
      "45/45 [==============================] - 0s 465us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/500\n",
      "45/45 [==============================] - 0s 488us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/500\n",
      "45/45 [==============================] - 0s 465us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/500\n",
      "45/45 [==============================] - 0s 532us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/500\n",
      "45/45 [==============================] - 0s 576us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/500\n",
      "45/45 [==============================] - 0s 532us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/500\n",
      "45/45 [==============================] - 0s 465us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/500\n",
      "45/45 [==============================] - 0s 488us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/500\n",
      "45/45 [==============================] - 0s 532us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/500\n",
      "45/45 [==============================] - 0s 532us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/500\n",
      "45/45 [==============================] - 0s 588us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/500\n",
      "45/45 [==============================] - 0s 565us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/500\n",
      "45/45 [==============================] - 0s 466us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/500\n",
      "45/45 [==============================] - 0s 465us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/500\n",
      "45/45 [==============================] - 0s 532us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/500\n",
      "45/45 [==============================] - 0s 488us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/500\n",
      "45/45 [==============================] - 0s 465us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/500\n",
      "45/45 [==============================] - 0s 488us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/500\n",
      "45/45 [==============================] - 0s 488us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/500\n",
      "45/45 [==============================] - 0s 465us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/500\n",
      "45/45 [==============================] - 0s 444us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/500\n",
      "45/45 [==============================] - ETA: 0s - loss: 4364.5938 - accuracy: 0.0000e+0 - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/500\n",
      "45/45 [==============================] - 0s 377us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/500\n",
      "45/45 [==============================] - 0s 377us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/500\n",
      "45/45 [==============================] - 0s 377us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/500\n",
      "45/45 [==============================] - 0s 377us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/500\n",
      "45/45 [==============================] - 0s 377us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/500\n",
      "45/45 [==============================] - 0s 377us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/500\n",
      "45/45 [==============================] - 0s 377us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/500\n",
      "45/45 [==============================] - 0s 377us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/500\n",
      "45/45 [==============================] - 0s 465us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/500\n",
      "45/45 [==============================] - 0s 532us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/500\n",
      "45/45 [==============================] - 0s 576us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/500\n",
      "45/45 [==============================] - 0s 576us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/500\n",
      "45/45 [==============================] - 0s 532us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/500\n",
      "45/45 [==============================] - 0s 487us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/500\n",
      "45/45 [==============================] - 0s 377us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/500\n",
      "45/45 [==============================] - 0s 377us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/500\n",
      "45/45 [==============================] - 0s 388us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/500\n",
      "45/45 [==============================] - 0s 377us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/500\n",
      "45/45 [==============================] - 0s 410us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/500\n",
      "45/45 [==============================] - 0s 554us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/500\n",
      "45/45 [==============================] - 0s 532us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/500\n",
      "45/45 [==============================] - 0s 465us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/500\n",
      "45/45 [==============================] - 0s 598us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/500\n",
      "45/45 [==============================] - 0s 643us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/500\n",
      "45/45 [==============================] - ETA: 0s - loss: 4227.6250 - accuracy: 0.0000e+0 - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/500\n",
      "45/45 [==============================] - 0s 532us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/500\n",
      "45/45 [==============================] - 0s 731us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/500\n",
      "45/45 [==============================] - 0s 776us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/500\n",
      "45/45 [==============================] - 0s 665us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/500\n",
      "45/45 [==============================] - 0s 554us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/500\n",
      "45/45 [==============================] - 0s 598us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/500\n",
      "45/45 [==============================] - 0s 355us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/500\n",
      "45/45 [==============================] - 0s 377us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/500\n",
      "45/45 [==============================] - 0s 465us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/500\n",
      "45/45 [==============================] - 0s 577us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/500\n",
      "45/45 [==============================] - 0s 532us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/500\n",
      "45/45 [==============================] - 0s 554us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/500\n",
      "45/45 [==============================] - 0s 555us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/500\n",
      "45/45 [==============================] - 0s 643us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/500\n",
      "45/45 [==============================] - 0s 488us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/500\n",
      "45/45 [==============================] - 0s 576us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/500\n",
      "45/45 [==============================] - 0s 487us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/500\n",
      "45/45 [==============================] - 0s 374us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/500\n",
      "45/45 [==============================] - 0s 382us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/500\n",
      "45/45 [==============================] - 0s 465us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/500\n",
      "45/45 [==============================] - ETA: 0s - loss: 4164.1562 - accuracy: 0.0000e+0 - 0s 510us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/500\n",
      "45/45 [==============================] - 0s 488us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/500\n",
      "45/45 [==============================] - 0s 488us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/500\n",
      "45/45 [==============================] - 0s 576us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/500\n",
      "45/45 [==============================] - 0s 532us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/500\n",
      "45/45 [==============================] - 0s 532us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/500\n",
      "45/45 [==============================] - 0s 556us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/500\n",
      "45/45 [==============================] - 0s 512us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/500\n",
      "45/45 [==============================] - 0s 466us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/500\n",
      "45/45 [==============================] - 0s 467us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/500\n",
      "45/45 [==============================] - 0s 445us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/500\n",
      "45/45 [==============================] - 0s 581us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/500\n",
      "45/45 [==============================] - 0s 554us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/500\n",
      "45/45 [==============================] - 0s 554us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/500\n",
      "45/45 [==============================] - 0s 566us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/500\n",
      "45/45 [==============================] - 0s 558us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/500\n",
      "45/45 [==============================] - 0s 444us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/500\n",
      "45/45 [==============================] - 0s 377us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/500\n",
      "45/45 [==============================] - 0s 398us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/500\n",
      "45/45 [==============================] - 0s 470us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/500\n",
      "45/45 [==============================] - 0s 555us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/500\n",
      "45/45 [==============================] - 0s 578us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/500\n",
      "45/45 [==============================] - 0s 525us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/500\n",
      "45/45 [==============================] - ETA: 0s - loss: 4291.7188 - accuracy: 0.0000e+0 - 0s 510us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/500\n",
      "45/45 [==============================] - 0s 401us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/500\n",
      "45/45 [==============================] - 0s 645us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/500\n",
      "45/45 [==============================] - 0s 378us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/500\n",
      "45/45 [==============================] - 0s 666us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/500\n",
      "45/45 [==============================] - 0s 411us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/500\n",
      "45/45 [==============================] - 0s 412us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/500\n",
      "45/45 [==============================] - 0s 545us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/500\n",
      "45/45 [==============================] - 0s 533us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/500\n",
      "45/45 [==============================] - 0s 558us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/500\n",
      "45/45 [==============================] - 0s 532us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/500\n",
      "45/45 [==============================] - 0s 488us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/500\n",
      "45/45 [==============================] - 0s 466us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/500\n",
      "45/45 [==============================] - 0s 533us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/500\n",
      "45/45 [==============================] - ETA: 0s - loss: 4858.0938 - accuracy: 0.0000e+0 - 0s 443us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/500\n",
      "45/45 [==============================] - 0s 423us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/500\n",
      "45/45 [==============================] - 0s 490us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/500\n",
      "45/45 [==============================] - 0s 512us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/500\n",
      "45/45 [==============================] - 0s 556us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/500\n",
      "45/45 [==============================] - 0s 600us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/500\n",
      "45/45 [==============================] - 0s 511us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/500\n",
      "45/45 [==============================] - 0s 466us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/500\n",
      "45/45 [==============================] - 0s 512us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206/500\n",
      "45/45 [==============================] - 0s 466us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/500\n",
      "45/45 [==============================] - 0s 467us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/500\n",
      "45/45 [==============================] - 0s 577us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/500\n",
      "45/45 [==============================] - 0s 556us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/500\n",
      "45/45 [==============================] - 0s 444us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/500\n",
      "45/45 [==============================] - 0s 536us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/500\n",
      "45/45 [==============================] - 0s 554us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/500\n",
      "45/45 [==============================] - 0s 533us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/500\n",
      "45/45 [==============================] - 0s 555us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/500\n",
      "45/45 [==============================] - 0s 543us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/500\n",
      "45/45 [==============================] - 0s 621us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/500\n",
      "45/45 [==============================] - 0s 465us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/500\n",
      "45/45 [==============================] - 0s 444us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/500\n",
      "45/45 [==============================] - 0s 445us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/500\n",
      "45/45 [==============================] - 0s 445us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/500\n",
      "45/45 [==============================] - 0s 423us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/500\n",
      "45/45 [==============================] - 0s 426us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/500\n",
      "45/45 [==============================] - 0s 477us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/500\n",
      "45/45 [==============================] - 0s 544us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/500\n",
      "45/45 [==============================] - 0s 621us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/500\n",
      "45/45 [==============================] - 0s 488us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/500\n",
      "45/45 [==============================] - 0s 643us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/500\n",
      "45/45 [==============================] - 0s 665us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/500\n",
      "45/45 [==============================] - 0s 733us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/500\n",
      "45/45 [==============================] - 0s 620us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/500\n",
      "45/45 [==============================] - 0s 532us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/500\n",
      "45/45 [==============================] - 0s 532us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/500\n",
      "45/45 [==============================] - 0s 465us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/500\n",
      "45/45 [==============================] - 0s 554us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/500\n",
      "45/45 [==============================] - 0s 400us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/500\n",
      "45/45 [==============================] - 0s 400us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/500\n",
      "45/45 [==============================] - 0s 400us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/500\n",
      "45/45 [==============================] - 0s 400us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/500\n",
      "45/45 [==============================] - 0s 400us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/500\n",
      "45/45 [==============================] - 0s 410us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/500\n",
      "45/45 [==============================] - 0s 377us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/500\n",
      "45/45 [==============================] - 0s 424us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/500\n",
      "45/45 [==============================] - 0s 401us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/500\n",
      "45/45 [==============================] - 0s 400us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 400us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/500\n",
      "45/45 [==============================] - 0s 401us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/500\n",
      "45/45 [==============================] - 0s 400us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/500\n",
      "45/45 [==============================] - 0s 400us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/500\n",
      "45/45 [==============================] - 0s 379us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/500\n",
      "45/45 [==============================] - 0s 377us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/500\n",
      "45/45 [==============================] - 0s 377us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/500\n",
      "45/45 [==============================] - 0s 377us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/500\n",
      "45/45 [==============================] - 0s 377us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/500\n",
      "45/45 [==============================] - 0s 377us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/500\n",
      "45/45 [==============================] - 0s 377us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/500\n",
      "45/45 [==============================] - 0s 412us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/500\n",
      "45/45 [==============================] - 0s 437us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/500\n",
      "45/45 [==============================] - 0s 488us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/500\n",
      "45/45 [==============================] - 0s 465us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/500\n",
      "45/45 [==============================] - 0s 488us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/500\n",
      "45/45 [==============================] - 0s 532us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/500\n",
      "45/45 [==============================] - 0s 488us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/500\n",
      "45/45 [==============================] - 0s 554us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/500\n",
      "45/45 [==============================] - 0s 465us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/500\n",
      "45/45 [==============================] - ETA: 0s - loss: 4450.5938 - accuracy: 0.0000e+0 - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/500\n",
      "45/45 [==============================] - 0s 413us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/500\n",
      "45/45 [==============================] - 0s 465us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/500\n",
      "45/45 [==============================] - 0s 643us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/500\n",
      "45/45 [==============================] - 0s 598us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/500\n",
      "45/45 [==============================] - 0s 576us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/500\n",
      "45/45 [==============================] - 0s 620us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/500\n",
      "45/45 [==============================] - 0s 554us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/500\n",
      "45/45 [==============================] - 0s 532us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/500\n",
      "45/45 [==============================] - 0s 488us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/500\n",
      "45/45 [==============================] - 0s 576us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/500\n",
      "45/45 [==============================] - 0s 488us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/500\n",
      "45/45 [==============================] - 0s 444us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/500\n",
      "45/45 [==============================] - 0s 423us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/500\n",
      "45/45 [==============================] - 0s 403us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/500\n",
      "45/45 [==============================] - 0s 379us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/500\n",
      "45/45 [==============================] - 0s 423us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/500\n",
      "45/45 [==============================] - 0s 423us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/500\n",
      "45/45 [==============================] - 0s 401us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/500\n",
      "45/45 [==============================] - 0s 444us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/500\n",
      "45/45 [==============================] - 0s 400us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/500\n",
      "45/45 [==============================] - 0s 447us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/500\n",
      "45/45 [==============================] - 0s 423us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 424us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/500\n",
      "45/45 [==============================] - 0s 465us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/500\n",
      "45/45 [==============================] - 0s 424us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/500\n",
      "45/45 [==============================] - 0s 423us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/500\n",
      "45/45 [==============================] - 0s 400us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/500\n",
      "45/45 [==============================] - 0s 467us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/500\n",
      "45/45 [==============================] - 0s 468us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/500\n",
      "45/45 [==============================] - 0s 423us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/500\n",
      "45/45 [==============================] - 0s 445us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/500\n",
      "45/45 [==============================] - 0s 401us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/500\n",
      "45/45 [==============================] - 0s 467us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/500\n",
      "45/45 [==============================] - 0s 487us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/500\n",
      "45/45 [==============================] - 0s 689us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/500\n",
      "45/45 [==============================] - 0s 576us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/500\n",
      "45/45 [==============================] - 0s 535us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/500\n",
      "45/45 [==============================] - 0s 576us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/500\n",
      "45/45 [==============================] - 0s 488us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/500\n",
      "45/45 [==============================] - 0s 578us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/500\n",
      "45/45 [==============================] - 0s 581us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/500\n",
      "45/45 [==============================] - 0s 621us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/500\n",
      "45/45 [==============================] - 0s 401us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/500\n",
      "45/45 [==============================] - 0s 466us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/500\n",
      "45/45 [==============================] - 0s 410us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/500\n",
      "45/45 [==============================] - 0s 423us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/500\n",
      "45/45 [==============================] - 0s 423us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/500\n",
      "45/45 [==============================] - 0s 400us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/500\n",
      "45/45 [==============================] - 0s 489us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/500\n",
      "45/45 [==============================] - 0s 490us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/500\n",
      "45/45 [==============================] - 0s 423us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/500\n",
      "45/45 [==============================] - 0s 458us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/500\n",
      "45/45 [==============================] - 0s 465us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/500\n",
      "45/45 [==============================] - 0s 709us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 401/500\n",
      "45/45 [==============================] - 0s 488us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 402/500\n",
      "45/45 [==============================] - 0s 576us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 403/500\n",
      "45/45 [==============================] - 0s 643us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 404/500\n",
      "45/45 [==============================] - 0s 710us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 405/500\n",
      "45/45 [==============================] - 0s 555us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 406/500\n",
      "45/45 [==============================] - 0s 488us/step - loss: 4316.0890 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 407/500\n",
      "45/45 [==============================] - 0s 534us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 408/500\n",
      "45/45 [==============================] - 0s 465us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 409/500\n",
      "45/45 [==============================] - 0s 466us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 410/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 410us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 411/500\n",
      "45/45 [==============================] - 0s 444us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 412/500\n",
      "45/45 [==============================] - 0s 423us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 413/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 414/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 415/500\n",
      "45/45 [==============================] - 0s 466us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 416/500\n",
      "45/45 [==============================] - 0s 583us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 417/500\n",
      "45/45 [==============================] - 0s 532us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 418/500\n",
      "45/45 [==============================] - 0s 576us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 419/500\n",
      "45/45 [==============================] - 0s 644us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 420/500\n",
      "45/45 [==============================] - 0s 598us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 421/500\n",
      "45/45 [==============================] - 0s 534us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 422/500\n",
      "45/45 [==============================] - 0s 580us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 423/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 424/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 425/500\n",
      "45/45 [==============================] - 0s 400us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 426/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 427/500\n",
      "45/45 [==============================] - 0s 390us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 428/500\n",
      "45/45 [==============================] - 0s 400us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 429/500\n",
      "45/45 [==============================] - 0s 444us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 430/500\n",
      "45/45 [==============================] - 0s 401us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 431/500\n",
      "45/45 [==============================] - 0s 444us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 432/500\n",
      "45/45 [==============================] - 0s 423us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 433/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 434/500\n",
      "45/45 [==============================] - 0s 379us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 435/500\n",
      "45/45 [==============================] - 0s 400us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 436/500\n",
      "45/45 [==============================] - 0s 403us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 437/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 438/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 439/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 440/500\n",
      "45/45 [==============================] - 0s 423us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 441/500\n",
      "45/45 [==============================] - 0s 444us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 442/500\n",
      "45/45 [==============================] - 0s 400us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 443/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 444/500\n",
      "45/45 [==============================] - 0s 377us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 445/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 446/500\n",
      "45/45 [==============================] - 0s 400us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 447/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 448/500\n",
      "45/45 [==============================] - 0s 423us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 449/500\n",
      "45/45 [==============================] - 0s 469us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 450/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 451/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 452/500\n",
      "45/45 [==============================] - 0s 377us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 453/500\n",
      "45/45 [==============================] - 0s 511us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 454/500\n",
      "45/45 [==============================] - 0s 477us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 455/500\n",
      "45/45 [==============================] - 0s 488us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 456/500\n",
      "45/45 [==============================] - 0s 516us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 457/500\n",
      "45/45 [==============================] - 0s 532us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 458/500\n",
      "45/45 [==============================] - 0s 488us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 459/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 460/500\n",
      "45/45 [==============================] - 0s 491us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 461/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 462/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 463/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 464/500\n",
      "45/45 [==============================] - 0s 375us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 465/500\n",
      "45/45 [==============================] - 0s 402us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 466/500\n",
      "45/45 [==============================] - 0s 402us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 467/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 468/500\n",
      "45/45 [==============================] - 0s 457us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 469/500\n",
      "45/45 [==============================] - 0s 422us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 470/500\n",
      "45/45 [==============================] - 0s 402us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 471/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 472/500\n",
      "45/45 [==============================] - 0s 401us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 473/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 474/500\n",
      "45/45 [==============================] - 0s 426us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 475/500\n",
      "45/45 [==============================] - 0s 621us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 476/500\n",
      "45/45 [==============================] - 0s 400us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 477/500\n",
      "45/45 [==============================] - 0s 424us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 478/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 479/500\n",
      "45/45 [==============================] - 0s 401us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 480/500\n",
      "45/45 [==============================] - 0s 489us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 481/500\n",
      "45/45 [==============================] - 0s 423us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 482/500\n",
      "45/45 [==============================] - 0s 426us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 483/500\n",
      "45/45 [==============================] - 0s 443us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 484/500\n",
      "45/45 [==============================] - ETA: 0s - loss: 4338.2812 - accuracy: 0.0000e+0 - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 485/500\n",
      "45/45 [==============================] - 0s 576us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 486/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 487/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 488/500\n",
      "45/45 [==============================] - 0s 753us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 489/500\n",
      "45/45 [==============================] - 0s 702us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 490/500\n",
      "45/45 [==============================] - 0s 643us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 491/500\n",
      "45/45 [==============================] - 0s 532us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 492/500\n",
      "45/45 [==============================] - 0s 488us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 493/500\n",
      "45/45 [==============================] - 0s 532us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 494/500\n",
      "45/45 [==============================] - 0s 510us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 495/500\n",
      "45/45 [==============================] - 0s 465us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 496/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 497/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 498/500\n",
      "45/45 [==============================] - 0s 421us/step - loss: 4316.0888 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 499/500\n",
      "45/45 [==============================] - 0s 399us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 500/500\n",
      "45/45 [==============================] - 0s 488us/step - loss: 4316.0889 - accuracy: 0.0000e+00 - val_loss: 3644.2000 - val_accuracy: 0.0000e+00\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import keras\n",
    "from keras.models import Sequential  # 뇌, 건물\n",
    "from keras.layers import Dense       # 한 층\n",
    "from keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(35,), activation='relu')) # 1층\n",
    "model.add(Dense(256, activation='relu'))  # 2층\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='softmax')) # 3층\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(hist.history['loss'])      # 훈련 비용\n",
    "plt.plot(hist.history['val_loss'])  # 검증 비용\n",
    "plt.plot(hist.history['accuracy'])       # 훈련 정확도\n",
    "plt.plot(hist.history['val_accuracy'])   # 검증 정확도\n",
    "plt.legend(['loss','val_loss','acc','val_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기울기: [[  0.04029489   0.17063629   0.03923829   0.06050389   0.3467572\n",
      "    0.56360787   0.85835075   0.07066596  -2.54506612  -0.27325483\n",
      "    0.07388066  -0.26295225  -0.1496099   -0.04147524   1.40315362\n",
      "    4.00538155  -3.46452941   0.75689156  -0.18931358  -0.2445803\n",
      "    0.23195115   0.0504965   -0.13089647  13.94032442   3.15463139\n",
      "  -17.15442152  -1.36703057   0.55219825   9.13724871   3.012757\n",
      "   -0.41464454   0.23195115   0.0504965   -0.04166103  -0.15864217]]\n",
      "절편: [63.32097972]\n",
      "훈련 정확도:1.00\n",
      "테스트 정확도:1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "print(\"기울기:\", lr.coef_)  # [0.39390555]\n",
    "print(\"절편:\", lr.intercept_)  # -0.03180434302675973\n",
    "print(\"훈련 정확도:{:.2f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"테스트 정확도:{:.2f}\".format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K이웃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "for i in range(1,46):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    print(knn.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
